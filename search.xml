<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Hello World</title>
      <link href="/2021/12/05/hello-world/"/>
      <url>/2021/12/05/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo generate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo deploy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>ML with sklearn——01 Decision Tree</title>
      <link href="/2020/01/20/ml-with-sklearn-01/"/>
      <url>/2020/01/20/ml-with-sklearn-01/</url>
      
        <content type="html"><![CDATA[<img src="/img/dt.jpeg" width="500" height="350"><span id="more"></span><h2 id="决策树和决策树学习"><a href="#决策树和决策树学习" class="headerlink" title="决策树和决策树学习"></a>决策树和决策树学习</h2><p>决策树：</p><blockquote><p>A <strong>decision tree</strong> is a decision support tool that uses a tree-like model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is one way to display an algorithm that only contains conditional control statements.</p></blockquote><p>决策树是一种决策支撑工具，它使用类似于树的决策模型及其可能的结果，包括机会事件结果、资源成本和效用。这是一种展示只包含条件控制语句算法的方法。</p><p>决策树学习：</p><blockquote><p><strong>Decision tree learning</strong> is one of the predictive modeling approaches used in statistics, data mining and machine learning. It uses a decision tree (as a predictive model) to go from observations about an item (represented in the branches) to conclusions about the item’s target value (represented in the leaves). Tree models where the target variable can take a discrete set of values are called <strong>classification trees</strong>; in these tree structures, leavesrepresent class labels and branches represent conjunctions of features that lead to those class labels. Decision trees where the target variable can take continuous values (typically real numbers) are called <strong>regression trees</strong>.</p></blockquote><p>决策树学习是统计、数据挖掘和机器学习中常用的预测建模方法之一。它使用一个决策树(作为一个预测模型)从对一个项目的观察(在分支中表示)到对项目目标值的结论(在叶子中表示)。目标变量可以取一组离散值的树模型称为分类树;在这些树结构中，叶子代表类标签，而分支代表导致这些类标签的特征连接。目标变量可以取连续值(通常是实数)的决策树称为回归树。</p><h3 id="决策树是如何工作的"><a href="#决策树是如何工作的" class="headerlink" title="决策树是如何工作的"></a>决策树是如何工作的</h3><p>决策树本质上是一种树形结构，既然是树结构，就包含节点和边。决策树是由节点(node)和有向边(directed edge)组成。而针对分类问题，决策过程，其实就是对记录的特征进行提问。最初的问题所在的地方就是<strong>根节点</strong>，在得到结论前的每一个问题都是<strong>中间节点</strong>，而得到的每一个结论都是<strong>叶子节点</strong>。</p><blockquote><p><strong>关键概念：节点</strong></p><p>根节点：没有进边，只有出边。包含最初的，针对特征的提问。</p><p>中间节点：既有进边也有出边，进边只有一条，出边可以有多条。都是针对特征的提问。</p><p>叶子节点：只有进边，没有出边，每个叶子节点都是一个类别标签(分类问题中)。</p><p>子节点和父节点：在两个相邻的节点中，更接近根节点的是父节点，另一个是子节点。</p></blockquote><h3 id="决策树的核心问题"><a href="#决策树的核心问题" class="headerlink" title="决策树的核心问题"></a>决策树的核心问题</h3><ol><li>如何从数据中找到最佳节点和最佳分支？</li><li>如何让决策树停止生长，防止过拟合？</li></ol><p>几乎所有的决策树有关的模型调整方法，都围绕这两个问题展开。</p><h2 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h2><p>如何从特征中寻找最佳特征，也就是如何从数据中找到最佳节点。对于分类树来说，衡量这个”最佳”的指标叫做<code>不纯度（impurity</code>。通常来说，不纯度越低，决策树对训练集的拟合越好。不纯度是基于节点来计算，树种的每个节点都会有一个不纯度，并且子节点的不纯度一定是低于父节点的，也就是说，，在同一颗决策树上，叶子节点的不纯度一定是最低的。不纯度可以通过<code>信息增益(Information Gain)</code>和<code>基尼指数(Gini index)</code>来计算。</p><h3 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h3><p>为了说明什么是信息增益，需要首先解释什么是<code>熵</code>和<code>条件熵</code>。</p><h3 id="信息增益比"><a href="#信息增益比" class="headerlink" title="信息增益比"></a>信息增益比</h3><h3 id="基尼指数"><a href="#基尼指数" class="headerlink" title="基尼指数"></a>基尼指数</h3><h2 id="决策树的生成"><a href="#决策树的生成" class="headerlink" title="决策树的生成"></a>决策树的生成</h2><h3 id="ID3"><a href="#ID3" class="headerlink" title="ID3"></a>ID3</h3><h3 id="C4-5"><a href="#C4-5" class="headerlink" title="C4.5"></a>C4.5</h3><h3 id="CART"><a href="#CART" class="headerlink" title="CART"></a>CART</h3><h2 id="Scikit-learn中的决策树"><a href="#Scikit-learn中的决策树" class="headerlink" title="Scikit-learn中的决策树"></a>Scikit-learn中的决策树</h2><p>sklearn中的决策树的类都在 <code>tree</code>这个模块下。这个模块总共包含5个类。</p><table><thead><tr><th>类</th><th>描述</th></tr></thead><tbody><tr><td>tree.DecisionTreeClassifier</td><td>分类树</td></tr><tr><td>tree.DecisionTreeRegressor</td><td>回归树</td></tr><tr><td>tree.export_graphviz</td><td>将生成的决策树导出为DOT格式，画图专用</td></tr><tr><td>tree.ExtraTreeClassifier</td><td>高随机版本的分类树</td></tr><tr><td>tree.ExtraTreeRegressor</td><td>高随机版本的回归树</td></tr></tbody></table><p>sklearn建模基本流程，三步走：</p><ol><li>实例化，建立模型对象</li><li>通过模型接口训练模型</li><li>通过模型接口提取需要的信息</li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn <span class="token keyword">import</span> tree  <span class="token comment"># 导入需要的模块 </span>clf <span class="token operator">=</span> tree<span class="token punctuation">.</span>DecisionTreeClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 实例化</span>clf <span class="token operator">=</span> clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>  <span class="token comment"># 用训练集数据训练模型</span>result <span class="token operator">=</span> clf<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span>  <span class="token comment"># 导入测试集，从接口中调用需要的信息</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="DecisionTreeClassifier"><a href="#DecisionTreeClassifier" class="headerlink" title="DecisionTreeClassifier"></a>DecisionTreeClassifier</h3><pre class="line-numbers language-none"><code class="language-none">sklearn.tree.DecisionTreeClassifier(criterion&#x3D;&#39;gini&#39;, splitter&#x3D;&#39;best&#39;, max_depth&#x3D;None,                                     min_samples_split&#x3D;2, min_samples_leaf&#x3D;1,                                     min_weight_fraction_leaf&#x3D;0.0, max_features&#x3D;None,                                     random_state&#x3D;None, max_leaf_nodes&#x3D;None,                                     min_impurity_decrease&#x3D;0.0, min_impurity_split&#x3D;None,                                     class_weight&#x3D;None, presort&#x3D;False)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="重要参数"><a href="#重要参数" class="headerlink" title="重要参数"></a>重要参数</h4><table><thead><tr><th>参数</th><th>如何影响模型</th><th>可能的输入有哪些</th><th>怎样选取参数</th></tr></thead><tbody><tr><td>criterion</td><td>确定不纯度的方法，帮忙找出最佳节点和最佳分支，不纯度越低，决策树对训练集的拟合越好</td><td>1. 不填默认基尼系数<br>2. 填写gini使用基尼系数<br>3. 填写entropy使用信息增益</td><td>1. 通常使用基尼系数<br> 2. 数据维度很大，噪音很大时使用基尼系数<br> 3. 数据维度低，数据比较清晰的时候，信息熵和基尼系数没有区别 <br>4. 当决策树拟合不够的时候，使用信息熵<br>5. 两个都试试，不好换另一个</td></tr><tr><td>random_state</td><td>设置分支中的随机模式的参数</td><td>默认None</td><td>可写任一数字</td></tr><tr><td>splitter</td><td>也是用来控制决策树的随机选项</td><td>1. best(默认)<br>2.random</td><td></td></tr><tr><td>max_depth</td><td>限制树的最大深度，超过设定深度的树枝全部剪掉</td><td>默认None</td><td>这是用得最广泛的剪枝参数，在高维度低样本量时非常有效。决策树多生长一层，对样本量的需求会增加一倍，所 以限制树深度能够有效地限制过拟合。在集成算法中也非常实用。实际使用时，建议从=3开始尝试，看看拟合的效 果再决定是否增加设定深度。</td></tr><tr><td>min_samples_split</td><td>一个节点必须要包含至少min_samples_split个样本，这个节点才允许被分支，否则分支不会发生</td><td></td><td></td></tr><tr><td>min_samples_leaf</td><td>一个节点在分之后每个节点都必须包含至少min_samples_leaf个训练样本，否则分支不会发生，或者，分枝会朝着满足每个子节点都包含min_samples_leaf个样本的方向去发生</td><td></td><td></td></tr><tr><td>max_features</td><td>max_features限制分枝时考虑的特征个数，超过限制个数的特征都会被舍弃</td><td></td><td></td></tr><tr><td>min_impurity_decrease</td><td>限制信息增益的大小，信息增益小于设定数值的分枝不会发生。这是在0.19版本中更新的 功能，在0.19版本之前时使用min_impurity_split。</td><td></td><td></td></tr><tr><td>class_weight</td><td></td><td></td><td></td></tr><tr><td>min_weight_fraction_leaf</td><td></td><td></td><td></td></tr></tbody></table><h4 id="重要属性和接口"><a href="#重要属性和接口" class="headerlink" title="重要属性和接口"></a>重要属性和接口</h4><ol><li>fit</li><li>score</li><li>Apply</li><li>predict</li><li>Feature_importances_</li></ol><h3 id="DecisionTreeRegressor"><a href="#DecisionTreeRegressor" class="headerlink" title="DecisionTreeRegressor"></a>DecisionTreeRegressor</h3><h4 id="一维回归图像的绘制"><a href="#一维回归图像的绘制" class="headerlink" title="一维回归图像的绘制"></a>一维回归图像的绘制</h4><pre class="line-numbers language-none"><code class="language-none">import numpy as npfrom sklearn.tree import DecisionTreeRegressorimport matplotlib.pyplot as plt# Create a random datasetrng &#x3D; np.random.RandomState(30)X &#x3D; np.sort(5 * rng.rand(80,1), axis&#x3D;0)y &#x3D; np.sin(X).ravel()y[::5] +&#x3D; 3 * (0.5 - rng.rand(16))# Fit regression modelreg1 &#x3D; DecisionTreeRegressor(max_depth&#x3D;2)reg2 &#x3D; DecisionTreeRegressor(max_depth&#x3D;5)reg1.fit(X,y)reg2.fit(X,y)# PredictX_test &#x3D; np.arange(0.0, 5.0, 0.01)[:, np.newaxis]y_1 &#x3D; reg1.predict(X_test)y_2 &#x3D; reg2.predict(X_test)# Plot the resultsplt.figure()plt.scatter(X, y ,s&#x3D;20, edgecolors&#x3D;&#39;black&#39;, c&#x3D;&#39;darkorange&#39;, label&#x3D;&#39;data&#39;)plt.plot(X_test, y_1, color&#x3D;&#39;cornflowerblue&#39;, label&#x3D;&#39;max_depth&#x3D;2&#39;, linewidth&#x3D;2)plt.plot(X_test, y_2, color&#x3D;&#39;yellowgreen&#39;, label&#x3D;&#39;max_depth&#x3D;5&#39;, linewidth&#x3D;2)plt.xlabel(&#39;data&#39;)plt.ylabel(&#39;target&#39;)plt.title(&#39;Decision Tree Regressor&#39;)plt.legend()plt.show()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="/img/DTR.png" width="500" height="350"><h2 id="决策树的优缺点"><a href="#决策树的优缺点" class="headerlink" title="决策树的优缺点"></a>决策树的优缺点</h2><ul><li>优点<ol><li>易于理解和解释，因为树木可以画出来被看见。</li><li>需要很少的数据准备。其他很多算法通常都需要数据规范化，需要创建虚拟变量并删除空值等。但请注意，sklearn中的决策树模块不支持对缺失值的处理。</li><li>使用树的成本(比如说，在预测数据的时候)是用于训练树的数据点的数量的对数，相比于其他算法，这是一个很低的成本。</li><li>能够同时处理数字和分类数据，既可以做回归又可以做分类。其他技术通常专门用于分析仅具有一种变量类型的数据集。</li><li>能够处理多输出问题，即含有多个标签的问题，注意与一个标签中含有多种标签分类的问题区别开。</li><li>是一个白盒模型，结果很容易能够被解释。如果在模型中可以观察到给定的情况，则可以通过布尔逻辑轻松 解释条件。相反，在黑盒模型中(例如，在人工神经网络中)，结果可能更难以解释。</li><li>可以使用统计测试验证模型，这让我们可以考虑模型的可靠性。</li><li>即使其假设在某种程度上违反了生成数据的真实模型，也能够表现良好。</li></ol></li><li>缺点<ol><li>决策树学习者可能创建过于复杂的树，这些树不能很好地推广数据。这称为过度拟合。修剪，设置叶节点所 需的最小样本数或设置树的最大深度等机制是避免此问题所必需的，而这些参数的整合和调整对初学者来说 会比较晦涩。</li><li>决策树可能不稳定，数据中微小的变化可能导致生成完全不同的树，这个问题需要通过集成算法来解决。</li><li>决策树的学习是基于贪婪算法，它靠优化局部最优(每个节点的最优)来试图达到整体的最优，但这种做法 不能保证返回全局最优决策树。这个问题也可以由集成算法来解决，在随机森林中，特征和样本会在分枝过 程中被随机采样。</li><li>有些概念很难学习，因为决策树不容易表达他们，例如XOR，奇偶校验或多路复用器问题。</li><li>如果标签中的某些类占主导地位，决策树学习者会创建偏向主导类的树。因此，建议在拟合决策树之前平衡数据集。</li></ol></li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>决策树(Decision Tree)是一种非参数的有监督学习方法，它能够从一系列有特征和标签的数据中总结出决策规则，并用树状图的结构来呈现这些规则，以解决分类和回归问题。决策树算法容易理解，适用各种数据，在解决各 种问题时都有良好表现，尤其是以树模型为核心的各种集成算法，在各个行业和领域都有广泛的应用。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>[1] weikipedia.Decision tree: <a href="https://en.wikipedia.org/wiki/Decision_tree">https://en.wikipedia.org/wiki/Decision_tree</a></p><p>[2] weikipedia.Decision tree learning: <a href="https://en.wikipedia.org/wiki/Decision_tree_learning">https://en.wikipedia.org/wiki/Decision_tree_learning</a></p><p>[3] scikit-learn官网. Decision Trees: <a href="https://scikit-learn.org/stable/modules/tree.html">https://scikit-learn.org/stable/modules/tree.html</a></p><p>[4] 李航. 统计学习方法. 第五章 决策树</p>]]></content>
      
      
      <categories>
          
          <category> MLDL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ml </tag>
            
            <tag> sklearn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elastic Getting Stared</title>
      <link href="/2018/02/26/elastic-get-started/"/>
      <url>/2018/02/26/elastic-get-started/</url>
      
        <content type="html"><![CDATA[<img src="/img/es.jpg" width="500" height="350"><span id="more"></span><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><h2 id="安装Elastic"><a href="#安装Elastic" class="headerlink" title="安装Elastic"></a>安装Elastic</h2><ol><li><p>安装elastic之前需要检查是否安装Java环境，Java版本至少是Java8</p><pre class="line-numbers language-none"><code class="language-none">$ java -versionjava version &quot;1.8.0_144&quot;Java(TM) SE Runtime Environment (build 1.8.0_144-b01)Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>安装elastic，最简单的方法是下载压缩包，并解压</p><pre class="line-numbers language-none"><code class="language-none">$ wget  https:&#x2F;&#x2F;artifacts.elastic.co&#x2F;downloads&#x2F;elasticsearch&#x2F;elasticsearch-6.2.2.tar.gz$ tar -xvf elasticsearch-6.2.2.tar.gz$ cd elasticsearch-6.2.2&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p>进入解压后的目录，运行如下命令，启动elastic</p><pre class="line-numbers language-none"><code class="language-none">$ .&#x2F;bin&#x2F;elasticsearch或者$ .&#x2F;bin&#x2F;elasticsearch -d -p pid<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p> 运行正常会出现如下界面，默认运行在<code>9200</code>端口</p><pre class="line-numbers language-none"><code class="language-none">$ .&#x2F;bin&#x2F;elasticsearch[2018-02-26T13:23:32,399][INFO ][o.e.n.Node               ] [] initializing ...[2018-02-26T13:23:32,455][INFO ][o.e.e.NodeEnvironment    ] [Ftxy5_l] using [1] data paths, mounts [[&#x2F; (&#x2F;dev&#x2F;disk1)]], net usable_space [133.8gb], net total_space [232.6gb], types [hfs][2018-02-26T13:23:32,456][INFO ][o.e.e.NodeEnvironment    ] [Ftxy5_l] heap size [989.8mb], compressed ordinary object pointers [true][2018-02-26T13:23:32,457][INFO ][o.e.n.Node               ] node name [Ftxy5_l] derived from node ID [Ftxy5_lYRBa67IuaMyOOBw]; set [node.name] to override[2018-02-26T13:23:32,457][INFO ][o.e.n.Node               ] version[6.2.2], pid[2242], build[10b1edd&#x2F;2018-02-16T19:01:30.685723Z], OS[Mac OS X&#x2F;10.12.6&#x2F;x86_64], JVM[Oracle Corporation&#x2F;Java HotSpot(TM) 64-Bit Server VM&#x2F;1.8.0_144&#x2F;25.144-b01][2018-02-26T13:23:32,458][INFO ][o.e.n.Node               ] JVM arguments [-Xms1g, -Xmx1g, -XX:+UseConcMarkSweepGC, -XX:CMSInitiatingOccupancyFraction&#x3D;75, -XX:+UseCMSInitiatingOccupancyOnly, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless&#x3D;true, -Dfile.encoding&#x3D;UTF-8, -Djna.nosys&#x3D;true, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe&#x3D;true, -Dio.netty.noKeySetOptimization&#x3D;true, -Dio.netty.recycler.maxCapacityPerThread&#x3D;0, -Dlog4j.shutdownHookEnabled&#x3D;false, -Dlog4j2.disable.jmx&#x3D;true, -Djava.io.tmpdir&#x3D;&#x2F;var&#x2F;folders&#x2F;yf&#x2F;m8nhcn4x1vd1snmnykt7n89h0000gn&#x2F;T&#x2F;elasticsearch.c7Lp6Ain, -XX:+HeapDumpOnOutOfMemoryError, -XX:+PrintGCDetails, -XX:+PrintGCDateStamps, -XX:+PrintTenuringDistribution, -XX:+PrintGCApplicationStoppedTime, -Xloggc:logs&#x2F;gc.log, -XX:+UseGCLogFileRotation, -XX:NumberOfGCLogFiles&#x3D;32, -XX:GCLogFileSize&#x3D;64m, -Des.path.home&#x3D;&#x2F;Users&#x2F;jockie&#x2F;install_programs&#x2F;elasticsearch-6.2.2, -Des.path.conf&#x3D;&#x2F;Users&#x2F;jockie&#x2F;install_programs&#x2F;elasticsearch-6.2.2&#x2F;config][2018-02-26T13:23:32,950][INFO ][o.e.p.PluginsService     ] [Ftxy5_l] loaded module [aggs-matrix-stats][2018-02-26T13:23:32,950][INFO ][o.e.p.PluginsService     ] [Ftxy5_l] loaded module [analysis-common][2018-02-26T13:23:32,950][INFO ][o.e.p.PluginsService     ] [Ftxy5_l] loaded module [ingest-common][2018-02-26T13:23:32,950][INFO ][o.e.p.PluginsService     ] [Ftxy5_l] loaded module [lang-expression][2018-02-26T13:23:32,950][INFO ][o.e.p.PluginsService     ] [Ftxy5_l] loaded module [lang-mustache][2018-02-26T13:23:32,950][INFO ][o.e.p.PluginsService     ] [Ftxy5_l] loaded module [lang-painless][2018-02-26T13:23:32,950][INFO ][o.e.p.PluginsService     ] [Ftxy5_l] loaded module [mapper-extras][2018-02-26T13:23:32,951][INFO ][o.e.p.PluginsService     ] [Ftxy5_l] loaded module [parent-join][2018-02-26T13:23:32,951][INFO ][o.e.p.PluginsService     ] [Ftxy5_l] loaded module [percolator][2018-02-26T13:23:32,951][INFO ][o.e.p.PluginsService     ] [Ftxy5_l] loaded module [rank-eval][2018-02-26T13:23:32,951][INFO ][o.e.p.PluginsService     ] [Ftxy5_l] loaded module [reindex][2018-02-26T13:23:32,951][INFO ][o.e.p.PluginsService     ] [Ftxy5_l] loaded module [repository-url][2018-02-26T13:23:32,951][INFO ][o.e.p.PluginsService     ] [Ftxy5_l] loaded module [transport-netty4][2018-02-26T13:23:32,951][INFO ][o.e.p.PluginsService     ] [Ftxy5_l] loaded module [tribe][2018-02-26T13:23:32,952][INFO ][o.e.p.PluginsService     ] [Ftxy5_l] no plugins loaded[2018-02-26T13:23:34,693][INFO ][o.e.d.DiscoveryModule    ] [Ftxy5_l] using discovery type [zen][2018-02-26T13:23:35,115][INFO ][o.e.n.Node               ] initialized[2018-02-26T13:23:35,115][INFO ][o.e.n.Node               ] [Ftxy5_l] starting ...[2018-02-26T13:23:35,226][INFO ][o.e.t.TransportService   ] [Ftxy5_l] publish_address &#123;127.0.0.1:9300&#125;, bound_addresses &#123;[::1]:9300&#125;, &#123;127.0.0.1:9300&#125;[2018-02-26T13:23:38,273][INFO ][o.e.c.s.MasterService    ] [Ftxy5_l] zen-disco-elected-as-master ([0] nodes joined), reason: new_master &#123;Ftxy5_l&#125;&#123;Ftxy5_lYRBa67IuaMyOOBw&#125;&#123;wcDZCO9STL-OfnTbGDNI_g&#125;&#123;127.0.0.1&#125;&#123;127.0.0.1:9300&#125;[2018-02-26T13:23:38,277][INFO ][o.e.c.s.ClusterApplierService] [Ftxy5_l] new_master &#123;Ftxy5_l&#125;&#123;Ftxy5_lYRBa67IuaMyOOBw&#125;&#123;wcDZCO9STL-OfnTbGDNI_g&#125;&#123;127.0.0.1&#125;&#123;127.0.0.1:9300&#125;, reason: apply cluster state (from master [master &#123;Ftxy5_l&#125;&#123;Ftxy5_lYRBa67IuaMyOOBw&#125;&#123;wcDZCO9STL-OfnTbGDNI_g&#125;&#123;127.0.0.1&#125;&#123;127.0.0.1:9300&#125; committed version [1] source [zen-disco-elected-as-master ([0] nodes joined)]])[2018-02-26T13:23:38,290][INFO ][o.e.h.n.Netty4HttpServerTransport] [Ftxy5_l] publish_address &#123;127.0.0.1:9200&#125;, bound_addresses &#123;[::1]:9200&#125;, &#123;127.0.0.1:9200&#125;[2018-02-26T13:23:38,290][INFO ][o.e.n.Node               ] [Ftxy5_l] started[2018-02-26T13:23:38,295][INFO ][o.e.g.GatewayService     ] [Ftxy5_l] recovered [0] indices into cluster_state<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>打开另一个terminal，运行以下命令，查看说明信息</p><pre class="line-numbers language-none"><code class="language-none">$ http http:&#x2F;&#x2F;127.0.0.1:9200HTTP&#x2F;1.1 200 OKcontent-encoding: gzipcontent-length: 280content-type: application&#x2F;json; charset&#x3D;UTF-8&#123;    &quot;cluster_name&quot;: &quot;elasticsearch&quot;,    &quot;cluster_uuid&quot;: &quot;IkkdQBGTSIGucxbOrB2OiA&quot;,    &quot;name&quot;: &quot;Ftxy5_l&quot;,    &quot;tagline&quot;: &quot;You Know, for Search&quot;,    &quot;version&quot;: &#123;        &quot;build_date&quot;: &quot;2018-02-16T19:01:30.685723Z&quot;,        &quot;build_hash&quot;: &quot;10b1edd&quot;,        &quot;build_snapshot&quot;: false,        &quot;lucene_version&quot;: &quot;7.2.1&quot;,        &quot;minimum_index_compatibility_version&quot;: &quot;5.0.0&quot;,        &quot;minimum_wire_compatibility_version&quot;: &quot;5.6.0&quot;,        &quot;number&quot;: &quot;6.2.2&quot;    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> <code>http http://127.0.0.1:9200</code>    命令请求9200端口，elastic返回一个JSON对象，包含当前集群、节点、版本等信息。</p></li><li><p>停止elastic服务<br>终端按下<code>Ctrl+C</code>，terminal打印信息如下 或者使用命令`kill pid’</p><pre class="line-numbers language-none"><code class="language-none">^C[2018-02-26T13:31:31,983][INFO ][o.e.n.Node               ] [Ftxy5_l] stopping ...[2018-02-26T13:31:32,001][INFO ][o.e.n.Node               ] [Ftxy5_l] stopped[2018-02-26T13:31:32,001][INFO ][o.e.n.Node               ] [Ftxy5_l] closing ...[2018-02-26T13:31:32,008][INFO ][o.e.n.Node               ] [Ftxy5_l] closed<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>允许其他机器访问<br>默认情况下，Elastic 只允许本机访问，如果需要远程访问，可以修改 Elastic 安装目录的config/elasticsearch.yml文件，去掉network.host的注释，将它的值改成0.0.0.0，然后重新启动 Elastic。</p><pre class="line-numbers language-none"><code class="language-none">$ vi config&#x2F;elasticsearch.yml55 #network.host: 192.168.0.156 network.host: 0.0.0.0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="安装kibana"><a href="#安装kibana" class="headerlink" title="安装kibana"></a>安装kibana</h2><p>kibana安装方法和elastic类似</p><ol><li>下载解压包并解压<pre class="line-numbers language-none"><code class="language-none">$ wget  https:&#x2F;&#x2F;artifacts.elastic.co&#x2F;downloads&#x2F;kibana&#x2F;kibana-6.2.2-darwin-x86_64.tar.gz$ tar -xvf kibana-6.2.2-darwin-x86_64.tar.gz$ mv kibana-6.2.2-darwin-x86_64.tar.gz kibana-6.2.2$ cd kibana-6.2.2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li>修改配置文件<pre class="line-numbers language-none"><code class="language-none">$ vi config&#x2F;kibana.yml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>运行服务<pre class="line-numbers language-none"><code class="language-none">$ .&#x2F;bin&#x2F;kibana<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>使用kibana<br>打开浏览器，输入<a href="http://localhost:5601/">http://localhost:5601</a><img src="img/kibana.png"></li></ol><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><ol><li>Near Realtime (NRT)<br> Elasticsearch是一个几乎实时的搜索平台。</li><li>Cluster &amp; Node<br> Elastic本质上是一个分布式数据库，可以运行在多台服务器上，每台服务器可以运行多个Elastic实例。一个Elastic实例称为一个节点（node），多个节点则组成一个集群（cluster）</li><li>Index<br> 和关系型数据库的数据库的概念一样，多条Document构成一个Index</li><li>Type<br> 按照<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/removal-of-types.html">规划</a> Elastic6.x版本已经不推荐使用，后面版本将会彻底移除</li><li>Document<br> Index里面的单条记录</li><li>Shards &amp; Replicas<br> 分片和副本</li></ol><h2 id="Exploring-Your-Cluster"><a href="#Exploring-Your-Cluster" class="headerlink" title="Exploring Your Cluster"></a>Exploring Your Cluster</h2><h3 id="Elasticsearch通过REST-API接口来操作"><a href="#Elasticsearch通过REST-API接口来操作" class="headerlink" title="Elasticsearch通过REST API接口来操作"></a>Elasticsearch通过REST API接口来操作</h3><ul><li>Check your cluster, node, and index health, status, and statistics</li><li>Administer your cluster, node, and index data and metadata</li><li>Perform CRUD (Create, Read, Update, and Delete) and search operations against your indexes</li><li>Execute advanced search operations such as paging, sorting, filtering, scripting, aggregations, and many others</li></ul><h3 id="查看集群的健康状况"><a href="#查看集群的健康状况" class="headerlink" title="查看集群的健康状况"></a>查看集群的健康状况</h3><pre class="line-numbers language-none"><code class="language-none">$ curl -XGET &#39;localhost:9200&#x2F;_cat&#x2F;health?v&amp;pretty&#39;epoch      timestamp cluster       status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent1519625839 14:17:19  elasticsearch green           1         1      0   0    0    0        0             0                  -                100.0%<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>通过以上可以看出，名为’elasticsearch’的集群正常运行，且状态为green<br>elasticsearch的健康状态分为：green，yellow，red</p><ul><li>Green - everything is good (cluster is fully functional)</li><li>Yellow - all data is available but some replicas are not yet allocated (cluster is fully functional)</li><li>Red - some data is not available for whatever reason (cluster is partially functional) </li></ul><h3 id="获取所有的节点信息"><a href="#获取所有的节点信息" class="headerlink" title="获取所有的节点信息"></a>获取所有的节点信息</h3><pre class="line-numbers language-none"><code class="language-none">$ curl -XGET &#39;localhost:9200&#x2F;_cat&#x2F;nodes?v&amp;pretty&#39;ip            heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name192.168.0.101           28          74   5    1.77                  mdi       *      Ftxy5_l<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="列出所有的index"><a href="#列出所有的index" class="headerlink" title="列出所有的index"></a>列出所有的index</h3><pre class="line-numbers language-none"><code class="language-none">$ curl -XGET &#39;localhost:9200&#x2F;_cat&#x2F;indices?v&amp;pretty&#39;health status index uuid pri rep docs.count docs.deleted store.size pri.store.size<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>以上说明，集群中目前还没有index</p><h3 id="新建Index"><a href="#新建Index" class="headerlink" title="新建Index"></a>新建Index</h3><p>以上操作，是在terminal下操作，接下来使用kibana console操作<br>PUT /customer?pretty<br>console展示如下：<br><img src="img/kibana_put.png" alt=""></p><h3 id="Index-and-Query-a-Document"><a href="#Index-and-Query-a-Document" class="headerlink" title="Index and Query a Document"></a>Index and Query a Document</h3><h4 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h4><pre class="line-numbers language-none"><code class="language-none">请求：PUT &#x2F;customer&#x2F;_doc&#x2F;1?pretty&#123;  &quot;name&quot;:&quot;John Doe&quot;&#125;响应：&#123;  &quot;_index&quot;: &quot;customer&quot;,  &quot;_type&quot;: &quot;_doc&quot;,  &quot;_id&quot;: &quot;1&quot;,  &quot;_version&quot;: 1,  &quot;result&quot;: &quot;created&quot;,  &quot;_shards&quot;: &#123;    &quot;total&quot;: 2,    &quot;successful&quot;: 1,    &quot;failed&quot;: 0  &#125;,  &quot;_seq_no&quot;: 0,  &quot;_primary_term&quot;: 1&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="Query"><a href="#Query" class="headerlink" title="Query"></a>Query</h4><pre class="line-numbers language-none"><code class="language-none">请求：GET &#x2F;customer&#x2F;_doc&#x2F;1?pretty响应：&#123;  &quot;_index&quot;: &quot;customer&quot;,  &quot;_type&quot;: &quot;_doc&quot;,  &quot;_id&quot;: &quot;1&quot;,  &quot;_version&quot;: 1,  &quot;found&quot;: true,  &quot;_source&quot;: &#123;    &quot;name&quot;: &quot;John Doe&quot;  &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="删除一个Index"><a href="#删除一个Index" class="headerlink" title="删除一个Index"></a>删除一个Index</h3><pre class="line-numbers language-none"><code class="language-none">请求：DELETE &#x2F;customer?pretty响应：&#123;  &quot;acknowledged&quot;: true&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>RESTAPI格式: <code>&lt;REST Verb&gt; /&lt;Index&gt;/&lt;Type&gt;/&lt;ID&gt;</code></p><ul><li>PUT /customer</li><li>PUT /customer/_doc/1<br>{<br>  “name”: “Jone Doe”<br>}</li><li>GET /customer/_doc/1</li><li>DELETE /customer</li></ul><h2 id="修改数据"><a href="#修改数据" class="headerlink" title="修改数据"></a>修改数据</h2><h3 id="Indexing-Replacing-Documents"><a href="#Indexing-Replacing-Documents" class="headerlink" title="Indexing/Replacing Documents"></a>Indexing/Replacing Documents</h3><pre class="line-numbers language-none"><code class="language-none">PUT &#x2F;customer&#x2F;_doc&#x2F;1?pretty&#123;  &quot;name&quot;: &quot;John Doe&quot;&#125;PUT &#x2F;customer&#x2F;_doc&#x2F;1?pretty&#123;  &quot;name&quot;: &quot;Jane Doe&quot;&#125;PUT &#x2F;customer&#x2F;_doc&#x2F;2?pretty&#123;  &quot;name&quot;: &quot;Jane Doe&quot;&#125;POST &#x2F;customer&#x2F;_doc?pretty&#123;  &quot;name&quot;: &quot;Jane Doe&quot;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Updating-Documents"><a href="#Updating-Documents" class="headerlink" title="Updating Documents"></a>Updating Documents</h3><pre class="line-numbers language-none"><code class="language-none">POST &#x2F;customer&#x2F;_doc&#x2F;1&#x2F;_update?pretty&#123;  &quot;doc&quot;: &#123; &quot;name&quot;: &quot;Jane Doe&quot; &#125;&#125;POST &#x2F;customer&#x2F;_doc&#x2F;1&#x2F;_update?pretty&#123;  &quot;doc&quot;: &#123; &quot;name&quot;: &quot;Jane Doe&quot;, &quot;age&quot;: 20 &#125;&#125;POST &#x2F;customer&#x2F;_doc&#x2F;1&#x2F;_update?pretty&#123;  &quot;script&quot; : &quot;ctx._source.age +&#x3D; 5&quot;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Deleting-Documents"><a href="#Deleting-Documents" class="headerlink" title="Deleting Documents"></a>Deleting Documents</h3><pre class="line-numbers language-none"><code class="language-none">DELETE &#x2F;customer&#x2F;_doc&#x2F;2?pretty<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="Batch-Processing"><a href="#Batch-Processing" class="headerlink" title="Batch Processing"></a>Batch Processing</h3><pre class="line-numbers language-none"><code class="language-none">POST &#x2F;customer&#x2F;_doc&#x2F;_bulk?pretty&#123;&quot;index&quot;:&#123;&quot;_id&quot;:&quot;1&quot;&#125;&#125;&#123;&quot;name&quot;: &quot;John Doe&quot; &#125;&#123;&quot;index&quot;:&#123;&quot;_id&quot;:&quot;2&quot;&#125;&#125;&#123;&quot;name&quot;: &quot;Jane Doe&quot; &#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-none"><code class="language-none">POST &#x2F;customer&#x2F;_doc&#x2F;_bulk?pretty&#123;&quot;update&quot;:&#123;&quot;_id&quot;:&quot;1&quot;&#125;&#125;&#123;&quot;doc&quot;: &#123; &quot;name&quot;: &quot;John Doe becomes Jane Doe&quot; &#125; &#125;&#123;&quot;delete&quot;:&#123;&quot;_id&quot;:&quot;2&quot;&#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Exploring-Your-Data"><a href="#Exploring-Your-Data" class="headerlink" title="Exploring Your Data"></a>Exploring Your Data</h2><h3 id="Sample-Dataset"><a href="#Sample-Dataset" class="headerlink" title="Sample Dataset"></a>Sample Dataset</h3><h3 id="Loading-the-Sample-Dataset"><a href="#Loading-the-Sample-Dataset" class="headerlink" title="Loading the Sample Dataset"></a>Loading the Sample Dataset</h3><pre class="line-numbers language-none"><code class="language-none">$ curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &quot;localhost:9200&#x2F;customer&#x2F;_doc&#x2F;_bulk?pretty&amp;refresh&quot; --data-binary &quot;@accounts.json&quot;$ curl &quot;localhost:9200&#x2F;_cat&#x2F;indices?v&quot;health status index    uuid                   pri rep docs.count docs.deleted store.size pri.store.sizeyellow open   customer ReKMezdYSWGfIvOUdMrBuQ   5   1       1000            0    478.2kb        478.2kb<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="The-Search-API"><a href="#The-Search-API" class="headerlink" title="The Search API"></a>The Search API</h3><h3 id="Introducing-the-Query-Language"><a href="#Introducing-the-Query-Language" class="headerlink" title="Introducing the Query Language"></a>Introducing the Query Language</h3><h3 id="Executing-Searches"><a href="#Executing-Searches" class="headerlink" title="Executing Searches"></a>Executing Searches</h3><h3 id="Executing-Filters"><a href="#Executing-Filters" class="headerlink" title="Executing Filters"></a>Executing Filters</h3><h3 id="Executing-Aggregations"><a href="#Executing-Aggregations" class="headerlink" title="Executing Aggregations"></a>Executing Aggregations</h3><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Elasticsearch是一个既简单有复杂的产品，通过REST APIs操作数据，返回json格式的数据。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>redis quickstart</title>
      <link href="/2018/02/25/redis-quickstart/"/>
      <url>/2018/02/25/redis-quickstart/</url>
      
        <content type="html"><![CDATA[<h2 id="Redis简介"><a href="#Redis简介" class="headerlink" title="Redis简介"></a>Redis简介</h2><h2 id="Redis键"><a href="#Redis键" class="headerlink" title="Redis键"></a>Redis键</h2><ul><li>KEYS pattern<br>  查找所有符合给定模式 pattern 的 key 。</li><li>EXISTS key<br>  检查给定 key 是否存在。</li><li>EXPIRE key seconds<br>  为给定 key 设置生存时间，当 key 过期时(生存时间为 0 )，它会被自动删除。</li><li>PEXPIRE key milliseconds<br>  这个命令和 EXPIRE 命令的作用类似，但是它以毫秒为单位设置 key 的生存时间，而不像 EXPIRE 命令那样，以秒为单位。</li><li>PERSIST key<br>  移除给定 key 的生存时间，将这个 key 从『易失的』(带生存时间 key )转换成『持久的』(一个不带生存时间、永不过期的 key )。</li><li>RANDOMKEY<br>  从当前数据库中随机返回(不删除)一个 key 。</li><li>TTL key<br>  以秒为单位，返回给定 key 的剩余生存时间(TTL, time to live)。</li><li>PTTL key<br>  这个命令类似于 TTL 命令，但它以毫秒为单位返回 key 的剩余生存时间，而不是像 TTL 命令那样，以秒为单位。</li><li>RENAME key newkey<br>  将 key 改名为 newkey 。当 key 和 newkey 相同，或者 key 不存在时，返回一个错误。当 newkey 已经存在时， RENAME 命令将覆盖旧值。</li><li>RENAMENX key newkey<br>  当且仅当 newkey 不存在时，将 key 改名为 newkey 。当 key 不存在时，返回一个错误。</li><li>TYPE key<br>  返回 key 所储存的值的类型。</li><li>DEL key [key …]<br>  删除给定的一个或多个 key 。不存在的 key 会被忽略。</li><li>FLUSHALL<br>  删除所有的key</li></ul><h2 id="Redis数据类型"><a href="#Redis数据类型" class="headerlink" title="Redis数据类型"></a>Redis数据类型</h2><ul><li>String(字符串)</li><li>Hash(哈希表)</li><li>List(列表)</li><li>Set(集合)</li><li>SortedSet(有序集合)</li></ul><h2 id="字符串操作"><a href="#字符串操作" class="headerlink" title="字符串操作"></a>字符串操作</h2><ul><li>SET key value [EX seconds] [PX milliseconds] [NX|XX]<br>  将字符串值 value 关联到 key 。如果 key 已经持有其他值， SET 就覆写旧值，无视类型。对于某个原本带有生存时间（TTL）的键来说， 当 SET 命令成功在这个键上执行时， 这个键原有的 TTL 将被清除。</li><li>MSET key value [key value …]<br>  同时设置一个或多个 key-value 对。</li><li>GET key<br>  返回 key 所关联的字符串值。如果 key 不存在那么返回特殊值 nil 。假如 key 储存的值不是字符串类型，返回一个错误，因为 GET 只能用于处理字符串值。</li><li>MGET key [key …]<br>  返回所有(一个或多个)给定 key 的值。</li><li>GETRANGE key start end<br>  返回 key 中字符串值的子字符串，字符串的截取范围由 start 和 end 两个偏移量决定(包括 start 和 end 在内)。<br>  负数偏移量表示从字符串最后开始计数， -1 表示最后一个字符， -2 表示倒数第二个，以此类推。<br>  GETRANGE 通过保证子字符串的值域(range)不超过实际字符串的值域来处理超出范围的值域请求。</li><li>GETSET key value<br>  将给定 key 的值设为 value ，并返回 key 的旧值(old value)。<br>  当 key 存在但不是字符串类型时，返回一个错误。</li><li>APPEND key value<br>  如果 key 已经存在并且是一个字符串， APPEND 命令将 value 追加到 key 原来的值的末尾。如果 key 不存在， APPEND 就简单地将给定 key 设为 value ，就像执行 SET key value 一样。</li><li>STRLEN key<br>  返回 key 所储存的字符串值的长度。</li><li>DECR key<br>  将 key 中储存的数字值减一。</li><li>DECRBY key decrement<br>  将 key 所储存的值减去减量 decrement 。</li><li>INCR key<br>  将 key 中储存的数字值增一。</li><li>INCRBY key increment<br>  将 key 所储存的值加上增量 increment 。</li><li>INCRBYFLOAT key increment<br>  为 key 中所储存的值加上浮点数增量 increment 。</li></ul><h2 id="哈希表操作"><a href="#哈希表操作" class="headerlink" title="哈希表操作"></a>哈希表操作</h2><ul><li>HSET key field value<br>  将哈希表 key 中的域 field 的值设为 value 。<br>  如果 key 不存在，一个新的哈希表被创建并进行 HSET 操作。<br>  如果域 field 已经存在于哈希表中，旧值将被覆盖。</li><li>HGET key field<br>  返回哈希表 key 中给定域 field 的值。</li><li>HDEL key field [field …]<br>  删除哈希表 key 中的一个或多个指定域，不存在的域将被忽略。</li><li>HKEYS key<br>  返回哈希表 key 中的所有域。</li><li>HVALS key<br>  返回哈希表 key 中所有域的值。</li><li>HLEN key<br>  返回哈希表 key 中域的数量。</li><li>HEXISTS key field<br>  查看哈希表 key 中，给定域 field 是否存在。</li><li>HMSET key field value [field value …]<br>  同时将多个 field-value (域-值)对设置到哈希表 key 中。<br>  此命令会覆盖哈希表中已存在的域。<br>  如果 key 不存在，一个空哈希表被创建并执行 HMSET 操作。</li></ul><h2 id="列表操作"><a href="#列表操作" class="headerlink" title="列表操作"></a>列表操作</h2><ul><li>LPUSH key value [value …]<br>  将一个或多个值 value 插入到列表 key 的表头</li><li>LRANGE key start stop<br>  返回列表 key 中指定区间内的元素，区间以偏移量 start 和 stop 指定。</li><li>LLEN key<br>  返回列表 key 的长度。</li></ul>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Road to Python Full Stack</title>
      <link href="/2018/01/21/road-to-python-full-stack/"/>
      <url>/2018/01/21/road-to-python-full-stack/</url>
      
        <content type="html"><![CDATA[<h2 id="python全栈之路"><a href="#python全栈之路" class="headerlink" title="python全栈之路"></a>python全栈之路</h2><h3 id="简单介绍"><a href="#简单介绍" class="headerlink" title="简单介绍"></a>简单介绍</h3><p>这篇文章记录一下，用Python做全栈开发的一些个人浅显感想。<br>首先python全栈有两个关键词，一个是<code>python</code>,一个是<code>全栈</code>。</p><p>首先说<code>python</code>:</p><ul><li>什么是python？<br>python是一种脚本语言，一种解释型语言，一种胶水语言。作为脚本语言，python可以写日常用的一些脚本任务；作为解释型语言，python可以直接通过命令行，验证自己的想法；作为胶水语言，python可以在程序中整合其他语言的脚本，比如C、Java等。</li><li>python有什么优势？<br>python语言简单优雅，容易入门，可以通过很短的代码实现复杂的功能。python内置许多标准函数和标准库，同时python拥有丰富的第三方库，可以应用在众多领域。</li><li>python的主要应用领域？<br>python语言简单，但不代表只能做简单的事情。从日常的脚本程序，web开发，爬虫开发到数据分析，机器学习，人工智能等领域，python都有丰富的库支持。<span id="more"></span>再说<code>全栈</code>：<br>英文：Full Stack，传统的开发分为前端和后端，而全栈就是结合前后端外加上各种相关知识，所以python全栈，不仅要会python相关领域的知识，同时也要会前端知识，比如html,css,javascript等前端必备知识。</li></ul><h3 id="必备知识"><a href="#必备知识" class="headerlink" title="必备知识"></a>必备知识</h3><ul><li>python 基础</li><li>python 高级</li><li>python Web开发</li><li>python 爬虫</li><li>python 数据分析</li></ul><p>说明：以上每个主题都涉及到很多内容，后期会按主题来更新相关内容，既是整理所学知识，同时也是巩固所学知识，以期以后能够熟练的运用所学知识，达到学有所用。<br>感想：深处当今这个互联网时代，知识爆发增长，学习永无止尽，我们不能为了学习而学习，摆脱知识焦虑，我们需要带着目标去学习，这样我们才会有一个明确的方向，不然就会淹没在这知识的海洋中。</p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HomeBrew简单使用</title>
      <link href="/2018/01/21/homebrew-jian-dan-shi-yong/"/>
      <url>/2018/01/21/homebrew-jian-dan-shi-yong/</url>
      
        <content type="html"><![CDATA[<h2 id="HomeBrew是什么"><a href="#HomeBrew是什么" class="headerlink" title="HomeBrew是什么?"></a>HomeBrew是什么?</h2><p>详情见<a href="https://brew.sh/">官网</a><br>HomeBrew是一款Mac OS平台下的软件管理工具，可以通过简单的命令安装、卸载、升级、管理软件。</p><h2 id="安装HomeBrew"><a href="#安装HomeBrew" class="headerlink" title="安装HomeBrew"></a>安装HomeBrew</h2><pre class="line-numbers language-none"><code class="language-none">&#x2F;usr&#x2F;bin&#x2F;ruby -e &quot;$(curl -fsSL https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Homebrew&#x2F;install&#x2F;master&#x2F;install)&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在终端输入以上命令，根据提示进行操作。</p><span id="more"></span><p>HomeBrew安装完成后，会在/usr/local下生成一个HomeBrew目录，</p><pre class="line-numbers language-none"><code class="language-none">&#x2F;usr&#x2F;local&#x2F;Homebrew<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>提供一个<code>brew</code>命令在/HomeBrew/bin目录下，</p><pre class="line-numbers language-none"><code class="language-none">jockie:&#x2F;usr&#x2F;local&#x2F;Homebrew&#x2F;bin (stable)$ lsbrew<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>并且在/usr/local/bin下生成一个链接</p><pre class="line-numbers language-none"><code class="language-none">jockie:&#x2F;usr&#x2F;local&#x2F;bin$ ll brewlrwxr-xr-x  1 jockie  admin    28B Jun  3  2017 brew -&gt; &#x2F;usr&#x2F;local&#x2F;Homebrew&#x2F;bin&#x2F;brew<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="brew管理软件"><a href="#brew管理软件" class="headerlink" title="brew管理软件"></a>brew管理软件</h2><ol><li>查看brew命令<pre class="line-numbers language-none"><code class="language-none">jockie:~$ brewExample usage:  brew search [TEXT|&#x2F;REGEX&#x2F;]  brew (info|home|options) [FORMULA...]  brew install FORMULA...  brew update  brew upgrade [FORMULA...]  brew uninstall FORMULA...  brew list [FORMULA...]Troubleshooting:  brew config  brew doctor  brew install -vd FORMULADevelopers:  brew create [URL [--no-fetch]]  brew edit [FORMULA...]  https:&#x2F;&#x2F;docs.brew.sh&#x2F;Formula-Cookbook.htmlFurther help:  man brew  brew help [COMMAND]  brew home<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><p>安装软件: brew install PKG_NAME<br>卸载软件: brew uninstall PKG_NAME<br>升级软件: brew upgrade PKG_NAME<br>更新brew: brew update<br>查看帮助:  brew help </p><p>说明：具体哪条命令不清楚，可以用帮助命令，比如查看update怎么使用，有没有什么参数：</p><pre class="line-numbers language-none"><code class="language-none">jockie:~$ brew update --helpbrew update [--merge] [--force]:    Fetch the newest version of Homebrew and all formulae from GitHub using    git(1) and perform any necessary migrations.    If --merge is specified then git merge is used to include updates    (rather than git rebase).    If --force (or -f) is specified then always do a slower, full update check even    if unnecessary.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>或者</p><pre class="line-numbers language-none"><code class="language-none">jockie:~$ brew help updatebrew update [--merge] [--force]:    Fetch the newest version of Homebrew and all formulae from GitHub using    git(1) and perform any necessary migrations.    If --merge is specified then git merge is used to include updates    (rather than git rebase).    If --force (or -f) is specified then always do a slower, full update check even    if unnecessary.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过brew方式，使我们在macOS系统下能够方便的管理软件。在使用brew的过程中，遇到不熟悉的命令，最简单的方式就是通过help方式查看具体操作信息。</p>]]></content>
      
      
      <categories>
          
          <category> mac </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tools </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>阿里云python3+flask部署</title>
      <link href="/2017/12/19/a-li-yun-python3-flask-bu-shu/"/>
      <url>/2017/12/19/a-li-yun-python3-flask-bu-shu/</url>
      
        <content type="html"><![CDATA[<h1 id="网站根目录"><a href="#网站根目录" class="headerlink" title="网站根目录"></a>网站根目录</h1><h1 id="普通www用户"><a href="#普通www用户" class="headerlink" title="普通www用户"></a>普通www用户</h1><p>pip install gunicorn<br>vim gunicorn<br>mkdir logs</p><h1 id="root用户"><a href="#root用户" class="headerlink" title="root用户"></a>root用户</h1><p>apt-get install supervisor</p>]]></content>
      
      
      <categories>
          
          <category> web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> flask </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>memcached简单使用</title>
      <link href="/2017/12/05/memcached-jian-dan-shi-yong/"/>
      <url>/2017/12/05/memcached-jian-dan-shi-yong/</url>
      
        <content type="html"><![CDATA[<img src="/img/memcached.jpg" width="500" height="350"><span id="more"></span><h2 id="什么是memcached"><a href="#什么是memcached" class="headerlink" title="什么是memcached"></a>什么是memcached</h2><p>Memcached 是一个高性能的分布式内存对象缓存系统，用于动态Web应用以减轻数据库负载。它通过在内存中缓存数据和对象来减少读取数据库的次数，从而提高动态、数据库驱动网站的速度。Memcached基于一个存储键/值对的hashmap。其守护进程（daemon ）是用C写的，但是客户端可以用任何语言来编写，并通过memcached协议与守护进程通信。</p><h2 id="安装memcached"><a href="#安装memcached" class="headerlink" title="安装memcached"></a>安装memcached</h2><h3 id="mac下安装"><a href="#mac下安装" class="headerlink" title="mac下安装"></a>mac下安装</h3><pre class="line-numbers language-none"><code class="language-none">brew install memcached<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>查看是否安装成功</p><pre class="line-numbers language-none"><code class="language-none">jockie:~$ which memcached&#x2F;usr&#x2F;local&#x2F;bin&#x2F;memcachedjockie:~$ brew list | grep memcachedmemcached<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="ubuntu下安装"><a href="#ubuntu下安装" class="headerlink" title="ubuntu下安装"></a>ubuntu下安装</h3><pre class="line-numbers language-none"><code class="language-none">sudo apt-get install memcached<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>查看是否安装成功</p><pre class="line-numbers language-none"><code class="language-none">:~$ which memcached &#x2F;usr&#x2F;bin&#x2F;memcached<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="启动memcached"><a href="#启动memcached" class="headerlink" title="启动memcached"></a>启动memcached</h2><pre class="line-numbers language-none"><code class="language-none">jockie:~$ memcached -d<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>-p 指定占用端口，默认11211</li><li>-d 让memcached在后台运行</li><li>-m 指定占用内存，单位为MB,默认64MB</li><li>-l 如果想要让别的机器连接，就必须设置-l 0.0.0.0</li></ul><h2 id="查看服务是否启动"><a href="#查看服务是否启动" class="headerlink" title="查看服务是否启动"></a>查看服务是否启动</h2><pre class="line-numbers language-none"><code class="language-none">jockie:~$ ps aux | grep memcachedjockie            4980   0.0  0.0  2442020   1992 s001  S+    7:12PM   0:00.00 grep memcachedjockie            4974   0.0  0.0  2480544   2484   ??  Ss    7:12PM   0:00.01 memcached -d<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="telnet操作memcached"><a href="#telnet操作memcached" class="headerlink" title="telnet操作memcached"></a>telnet操作memcached</h2><ol><li><p>连接和退出<br>连接: <code>telnet ip地址 [11211]</code><br>退出: <code>quit</code></p></li><li><p>基本命令</p><ul><li><p>存储命令</p><ul><li>基本语法：  <pre class="line-numbers language-none"><code class="language-none">command key flags exptime bytes [noreply] value <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li>参数说明：<ul><li>command: 存储命令，包含<code>set</code>/<code>add</code>/<code>replace</code>/<code>append</code>/<code>prepend</code></li><li>key: 键值 key-value 结构中的 key，用于查找缓存值。</li><li>flags: 可以包括键值对的整型参数，客户机使用它存储关于键值对的额外信息 。</li><li>exptime: 在缓存中保存键值对的时间长度（以秒为单位，0 表示永远）。</li><li>bytes: 在缓存中存储的字节数。</li><li>noreply(可选): 该参数告知服务器不需要返回数据。</li><li>value: 存储的值（始终位于第二行)（可直接理解为key-value结构中的value）。</li></ul></li><li>示例：  <pre class="line-numbers language-none"><code class="language-none">jockie:~$ telnet 127.0.0.1 11211Trying 127.0.0.1...Connected to localhost.Escape character is &#39;^]&#39;.set username 0 0 4jackSTOREDadd username 0 0 4johnNOT_STOREDadd pass 0 0 6123456STOREDreplace username 0 0 5peterSTOREDappend username 0 0 5athonSTOREDprepend pass 0 0 200STORED<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul></li><li><p>查找命令 </p><ul><li>基本语法  <pre class="line-numbers language-none"><code class="language-none">command key1 [key2 key3]<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>参数说明：<ul><li>command: 包含<code>get</code>/<code>gets</code>/<code>delete</code></li></ul></li><li>示例：  <pre class="line-numbers language-none"><code class="language-none">get usernameVALUE username 0 9johnathonENDget username passVALUE username 0 9johnathonVALUE pass 0 800123456ENDdelete passDELETEDget passEND<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul></li><li><p>自增自减命令</p><ul><li>基本语法：  <pre class="line-numbers language-none"><code class="language-none">command key value<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>参数说明：<ul><li>command： 包含<code>incr/decr</code></li><li>value: 自增或自减的值</li></ul></li><li>示例：  <pre class="line-numbers language-none"><code class="language-none">set height 0 0 3180STOREDget heightVALUE height 0 3180ENDincr height 5185get heightVALUE height 0 3185ENDdecr height 10175get heightVALUE height 0 3175END<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul></li><li><p>统计命令</p><ul><li>stats<pre class="line-numbers language-none"><code class="language-none">statsSTAT pid 4974STAT uptime 4990STAT time 1512477311STAT version 1.5.3STAT libevent 2.1.8-stableSTAT pointer_size 64STAT rusage_user 0.510169STAT rusage_system 0.355403STAT max_connections 1024STAT curr_connections 10STAT total_connections 20STAT rejected_connections 0STAT connection_structures 11STAT reserved_fds 20STAT cmd_get 27STAT cmd_set 19STAT cmd_flush 6STAT cmd_touch 0STAT get_hits 16STAT get_misses 11STAT get_expired 0STAT get_flushed 4STAT delete_misses 0STAT delete_hits 2STAT incr_misses 0STAT incr_hits 1STAT decr_misses 0STAT decr_hits 1STAT cas_misses 0STAT cas_hits 0STAT cas_badval 0STAT touch_hits 0STAT touch_misses 0STAT auth_cmds 0STAT auth_errors 0STAT bytes_read 1015STAT bytes_written 786STAT limit_maxbytes 67108864STAT accepting_conns 1STAT listen_disabled_num 0STAT time_in_listen_disabled_us 0STAT threads 4STAT conn_yields 0STAT hash_power_level 16STAT hash_bytes 524288STAT hash_is_expanding 0STAT slab_reassign_rescues 0STAT slab_reassign_chunk_rescues 0STAT slab_reassign_evictions_nomem 0STAT slab_reassign_inline_reclaim 0STAT slab_reassign_busy_items 0STAT slab_reassign_busy_deletes 0STAT slab_reassign_running 0STAT slabs_moved 0STAT lru_crawler_running 0STAT lru_crawler_starts 3315STAT lru_maintainer_juggles 8302STAT malloc_fails 0STAT log_worker_dropped 0STAT log_worker_written 0STAT log_watcher_skipped 0STAT log_watcher_sent 0STAT bytes 144STAT curr_items 2STAT total_items 15STAT slab_global_page_pool 0STAT expired_unfetched 0STAT evicted_unfetched 0STAT evicted_active 0STAT evictions 0STAT reclaimed 1STAT crawler_reclaimed 0STAT crawler_items_checked 2STAT lrutail_reflocked 0STAT moves_to_cold 16STAT moves_to_warm 5STAT moves_within_lru 0STAT direct_reclaims 0STAT lru_bumps_dropped 0END<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li>stats items<pre class="line-numbers language-none"><code class="language-none">stats itemsSTAT items:1:number 2STAT items:1:number_hot 0STAT items:1:number_warm 0STAT items:1:number_cold 2STAT items:1:age_hot 0STAT items:1:age_warm 0STAT items:1:age 705STAT items:1:evicted 0STAT items:1:evicted_nonzero 0STAT items:1:evicted_time 0STAT items:1:outofmemory 0STAT items:1:tailrepairs 0STAT items:1:reclaimed 1STAT items:1:expired_unfetched 0STAT items:1:evicted_unfetched 0STAT items:1:evicted_active 0STAT items:1:crawler_reclaimed 0STAT items:1:crawler_items_checked 2STAT items:1:lrutail_reflocked 0STAT items:1:moves_to_cold 16STAT items:1:moves_to_warm 5STAT items:1:moves_within_lru 0STAT items:1:direct_reclaims 0STAT items:1:hits_to_hot 5STAT items:1:hits_to_warm 0STAT items:1:hits_to_cold 11STAT items:1:hits_to_temp 0END<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li>stats slabs<pre class="line-numbers language-none"><code class="language-none">tats slabsSTAT 1:chunk_size 96STAT 1:chunks_per_page 10922STAT 1:total_pages 1STAT 1:total_chunks 10922STAT 1:used_chunks 2STAT 1:free_chunks 10920STAT 1:free_chunks_end 0STAT 1:mem_requested 144STAT 1:get_hits 16STAT 1:cmd_set 19STAT 1:delete_hits 2STAT 1:incr_hits 1STAT 1:decr_hits 1STAT 1:cas_hits 0STAT 1:cas_badval 0STAT 1:touch_hits 0STAT active_slabs 1STAT total_malloced 1048576END<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul></li><li><p>清理缓存命令</p><ul><li>基本语法：<pre class="line-numbers language-none"><code class="language-none">flush_all [time] [noreply]<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>参数说明：<br>  [time]可选参数，用于在指定时间执行清理缓存操作。</li><li>示例：<pre class="line-numbers language-none"><code class="language-none">flush_allOKget usernameENDget passEND<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul></li></ul></li></ol><h2 id="python操作memcached"><a href="#python操作memcached" class="headerlink" title="python操作memcached"></a>python操作memcached</h2><ol><li>安装<code>python-memcached</code>: <code>pip install python-memcached</code></li><li>连接memcached<pre class="line-numbers language-none"><code class="language-none">import memcachemc &#x3D; memcache.Client([&#39;127.0.0.1:11211&#39;], debug&#x3D;True)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li>设置数据<pre class="line-numbers language-none"><code class="language-none">mc.set(&#39;username&#39;, &#39;john&#39;, time&#x3D;60)mc.set(&#39;count&#39;,10,time&#x3D;60)mc.set_multi(&#123;&#39;gender&#39;: &#39;male&#39;, &#39;phone&#39;: &#39;111111&#39;&#125;, time&#x3D;60 * 2)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li>获取数据<pre class="line-numbers language-none"><code class="language-none">print(mc.get(&#39;phone&#39;))<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>删除数据<pre class="line-numbers language-none"><code class="language-none">mc.delete(&#39;gender&#39;)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>自增、自减<pre class="line-numbers language-none"><code class="language-none">mc.incr(&#39;count&#39;) # delta默认值为1mc.decr(&#39;count&#39;, delta&#x3D;3)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li></ol>]]></content>
      
      
      <categories>
          
          <category> database </category>
          
      </categories>
      
      
        <tags>
            
            <tag> memcached </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python built-in constants</title>
      <link href="/2017/11/15/python-built-in-constants/"/>
      <url>/2017/11/15/python-built-in-constants/</url>
      
        <content type="html"><![CDATA[<h2 id="python内置常量"><a href="#python内置常量" class="headerlink" title="python内置常量"></a>python内置常量</h2><h3 id="False"><a href="#False" class="headerlink" title="False"></a>False</h3><p>bool类型的假值，python3中，False作为一个关键字不能被赋值，赋值是非法的，会报语法错误：</p><pre><code>In [1]: False = 0  File &quot;&lt;ipython-input-1-389dfc15b373&gt;&quot;, line 1    False = 0             ^SyntaxError: can&#39;t assign to keyword</code></pre><h3 id="True"><a href="#True" class="headerlink" title="True"></a>True</h3><p>同False一样，bool类型的真值，python3中，True作为一个关键字不能被赋值，赋值是非法的，会报语法错误：</p><pre><code>In [1]: True = 1  File &quot;&lt;ipython-input-2-11e39cdf8368&gt;&quot;, line 1    True = 1            ^SyntaxError: can&#39;t assign to keyword</code></pre><span id="more"></span><h3 id="None"><a href="#None" class="headerlink" title="None"></a>None</h3><p>NoneType类型的唯一返回值，None通常被用来表示一个值得缺失，同样也不能被赋值</p><pre><code>In [1]: None = []  File &quot;&lt;ipython-input-4-263c1fbabdb8&gt;&quot;, line 1    None = []             ^SyntaxError: can&#39;t assign to keyword</code></pre><h3 id="NotImplemented"><a href="#NotImplemented" class="headerlink" title="NotImplemented"></a>NotImplemented</h3><h3 id="Ellipsis"><a href="#Ellipsis" class="headerlink" title="Ellipsis"></a>Ellipsis</h3><h3 id="debug"><a href="#debug" class="headerlink" title="__debug__"></a><code>__debug__</code></h3><p>如果不是以-o运行python，返回True</p><h3 id="quit-code-Node"><a href="#quit-code-Node" class="headerlink" title="quit(code=Node)"></a>quit(code=Node)</h3><h3 id="exit-code-None"><a href="#exit-code-None" class="headerlink" title="exit(code=None)"></a>exit(code=None)</h3><h3 id="copyright"><a href="#copyright" class="headerlink" title="copyright"></a>copyright</h3><pre><code>In [1]: copyrightOut[1]:Copyright (c) 2001-2016 Python Software Foundation.All Rights Reserved.Copyright (c) 2000 BeOpen.com.All Rights Reserved.Copyright (c) 1995-2001 Corporation for National Research Initiatives.All Rights Reserved.Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.All Rights Reserved.</code></pre><h3 id="license"><a href="#license" class="headerlink" title="license"></a>license</h3><pre><code>In [1]: licenseOut[1]: Type license() to see the full license textIn [2]: license()A. HISTORY OF THE SOFTWARE==========================Python was created in the early 1990s by Guido van Rossum at StichtingMathematisch Centrum (CWI, see http://www.cwi.nl) in the Netherlandsas a successor of a language called ABC.  Guido remains Python&#39;sprincipal author, although it includes many contributions from others.In 1995, Guido continued his work on Python at the Corporation forNational Research Initiatives (CNRI, see http://www.cnri.reston.va.us)in Reston, Virginia where he released several versions of thesoftware.In May 2000, Guido and the Python core development team moved toBeOpen.com to form the BeOpen PythonLabs team.  In October of the sameyear, the PythonLabs team moved to Digital Creations (now ZopeCorporation, see http://www.zope.com).  In 2001, the Python SoftwareFoundation (PSF, see http://www.python.org/psf/) was formed, anon-profit organization created specifically to own Python-relatedIntellectual Property.  Zope Corporation is a sponsoring member ofthe PSF.All Python releases are Open Source (see http://www.opensource.org forHit Return for more, or q (and Return) to quit:</code></pre><h3 id="credits"><a href="#credits" class="headerlink" title="credits"></a>credits</h3><pre><code>In [1]: creditsOut[1]:    Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands    for supporting Python development.  See www.python.org for more information.</code></pre>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> built-in constants </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python built-in functions</title>
      <link href="/2017/11/15/python-built-in-functions/"/>
      <url>/2017/11/15/python-built-in-functions/</url>
      
        <content type="html"><![CDATA[<h2 id="python内置函数"><a href="#python内置函数" class="headerlink" title="python内置函数"></a>python内置函数</h2><p>python解释器内置许多函数和类型，我们可以直接使用，下表按字典顺序列出</p><table><thead><tr><th></th><th></th><th>内置函数</th><th></th><th></th></tr></thead><tbody><tr><td><a href="#abs">abs()</a></td><td><a href="#dict">dict()</a></td><td><a href="#help">help()</a></td><td><a href="#min">min()</a></td><td><a href="#setattr">setattr()</a></td></tr><tr><td><a href="#all">all()</a></td><td><a href="#dir">dir()</a></td><td>hex()</td><td><a href="#next">next()</a></td><td><a href="#slice">slice()</a></td></tr><tr><td><a href="#any">any()</a></td><td><a href="#divmod">divmod()</a></td><td><a href="#id">id()</a></td><td><a href="#object">object()</a></td><td><a href="#sorted">sorted()</a></td></tr><tr><td><a href="#ascii">ascii()</a></td><td><a href="#enumerate">enumerate()</a></td><td><a href="#input">input()</a></td><td><a href="#oct">oct()</a></td><td><a href="#staticmethod">staticmethod()</a></td></tr><tr><td><a href="#bin">bin()</a></td><td><a href="#eval">eval()</a></td><td><a href="#int">int()</a></td><td><a href="#open">open()</a></td><td><a href="#str">str()</a></td></tr><tr><td><a href="#bool">bool()</a></td><td><a href="#exec">exec()</a></td><td><a href="#isinstance">isinstance()</a></td><td><a href="#ord">ord()</a></td><td><a href="#sum">sum()</a></td></tr><tr><td><a href="#bytearray">bytearray()</a></td><td><a href="#filter">filter()</a></td><td><a href="#issubclass">issubclass()</a></td><td><a href="#pow">pow()</a></td><td><a href="#super">super()</a></td></tr><tr><td><a href="#bytes">bytes()</a></td><td><a href="#float">float()</a></td><td><a href="#iter">iter()</a></td><td><a href="#print">print()</a></td><td><a href="#tuple">tuple()</a></td></tr><tr><td><a href="#callable">callable()</a></td><td><a href="#format">format()</a></td><td><a href="#len">len()</a></td><td><a href="#property">property()</a></td><td><a href="#type">type()</a></td></tr><tr><td><a href="#chr">chr()</a></td><td><a href="#frozenset">frozenset()</a></td><td><a href="#list">list()</a></td><td><a href="#range">range()</a></td><td><a href="vars">vars()</a></td></tr><tr><td><a href="#classmethod">classmethod()</a></td><td><a href="#getattr">getattr()</a></td><td><a href="#locals">locals()</a></td><td><a href="#repr">repr()</a></td><td><a href="#zip">zip()</a></td></tr><tr><td><a href="#compile">compile()</a></td><td><a href="#globals">globals()</a></td><td><a href="#map">map()</a></td><td><a href="#reversed">reversed()</a></td><td><a href="#import"><code>__import__()</code></a></td></tr><tr><td><a href="#complex">complex()</a></td><td><a href="#hasattr">hasattr()</a></td><td><a href="#max">max()</a></td><td><a href="#round">round()</a></td><td></td></tr><tr><td><a href="#delattr">delattr()</a></td><td><a href="#hash">hash()</a></td><td><a href="#memoryview">memoryview()</a></td><td><a href="set">set()</a></td><td></td></tr></tbody></table><span id="more"></span><h3 id="abs-x"><a href="#abs-x" class="headerlink" title="abs(x)"></a><span id='abs'>abs(x)</span></h3><p>返回一个数的绝对值。参数可以是一个整型或者浮点型。如果参数是一个复数的话，则返回magnitue</p><p>magnitude的计算规则如下： 实数的magnitude就是该实数的正平方根，如2的magnitude就是2，-3的magnitude就是3 复数的magnitude是该复数与共轭复数的乘积的正平方根，比如z=3-2j，则magnitude为<code>(3-2j)*(3+2j)</code>的正平方根，也就是9+4＝13的正平方根；<br>示例：    </p><pre><code>In [1]: abs(7)Out[1]: 7In [2]: abs(-7.7)Out[2]: 7.7In [3]: abs(complex(7,7))Out[3]: 9.899494936611665</code></pre><h3 id="all-iterable"><a href="#all-iterable" class="headerlink" title="all(iterable)"></a><span id='all'>all(iterable)</span></h3><p>参数为可迭代对象，如果对象的所有元素为真或者对象为空，则返回True，等价于：</p><pre><code>def all(iterable):    for element in iterable:        if not element:            return False    return True</code></pre><p>示例：</p><pre><code>In [6]: all([1,2,3])Out[6]: TrueIn [7]: all(())Out[7]: TrueIn [10]: all([1,2,3,None])Out[10]: False</code></pre><h3 id="any-iterable"><a href="#any-iterable" class="headerlink" title="any(iterable)"></a><span id='any'>any(iterable)</span></h3><p>参数为可迭代对象，如果对象的任一元素为真，则返回True，如果对象为空，则返回False，等价于：</p><pre><code>def any(iterable):    for element in iterable:        if element:            return True    return False</code></pre><p>示例：</p><pre><code>In [11]: any([True,False])Out[11]: TrueIn [12]: any(&#123;&#125;)Out[12]: False</code></pre><h3 id="ascii"><a href="#ascii" class="headerlink" title="ascii"></a><span id='ascii'>ascii</span></h3><h3 id="bin"><a href="#bin" class="headerlink" title="bin"></a><span id='bin'>bin</span></h3><h3 id="bool"><a href="#bool" class="headerlink" title="bool"></a><span id='bool'>bool</span></h3><h3 id="bytearray"><a href="#bytearray" class="headerlink" title="bytearray"></a><span id='bytearray'>bytearray</span></h3><h3 id="bytes"><a href="#bytes" class="headerlink" title="bytes"></a><span id='bytes'>bytes</span></h3><h3 id="callable"><a href="#callable" class="headerlink" title="callable"></a><span id='callable'>callable</span></h3><h3 id="chr"><a href="#chr" class="headerlink" title="chr"></a><span id='chr'>chr</span></h3><h3 id="classmethod"><a href="#classmethod" class="headerlink" title="classmethod"></a><span id='classmethod'>classmethod</span></h3><h3 id="compile"><a href="#compile" class="headerlink" title="compile"></a><span id='compile'>compile</span></h3><h3 id="complex"><a href="#complex" class="headerlink" title="complex"></a><span id='complex'>complex</span></h3><h3 id="delattr"><a href="#delattr" class="headerlink" title="delattr"></a><span id='delattr'>delattr</span></h3><h3 id="dict"><a href="#dict" class="headerlink" title="dict"></a><span id='dict'>dict</span></h3><h3 id="dir"><a href="#dir" class="headerlink" title="dir"></a><span id='dir'>dir</span></h3><h3 id="divmod"><a href="#divmod" class="headerlink" title="divmod"></a><span id='divmod'>divmod</span></h3><h3 id="enumerate"><a href="#enumerate" class="headerlink" title="enumerate"></a><span id='enumerate'>enumerate</span></h3><h3 id="eval"><a href="#eval" class="headerlink" title="eval"></a><span id='eval'>eval</span></h3><h3 id="exec"><a href="#exec" class="headerlink" title="exec"></a><span id='exec'>exec</span></h3><h3 id="filter"><a href="#filter" class="headerlink" title="filter"></a><span id='filter'>filter</span></h3><h3 id="float"><a href="#float" class="headerlink" title="float"></a><span id='float'>float</span></h3><h3 id="format"><a href="#format" class="headerlink" title="format"></a><span id='format'>format</span></h3><h3 id="frozenset"><a href="#frozenset" class="headerlink" title="frozenset"></a><span id='frozenset'>frozenset</span></h3><h3 id="getattr"><a href="#getattr" class="headerlink" title="getattr"></a><span id='getattr'>getattr</span></h3><h3 id="globals"><a href="#globals" class="headerlink" title="globals"></a><span id='globals'>globals</span></h3><h3 id="hasattr"><a href="#hasattr" class="headerlink" title="hasattr"></a><span id='hasattr'>hasattr</span></h3><h3 id="hash"><a href="#hash" class="headerlink" title="hash"></a><span id='hash'>hash</span></h3><h3 id="help"><a href="#help" class="headerlink" title="help"></a><span id='help'>help</span></h3><h3 id="hex"><a href="#hex" class="headerlink" title="hex"></a><span id='hex'>hex</span></h3><h3 id="id-object"><a href="#id-object" class="headerlink" title="id(object)"></a><span id='id'>id(object)</span></h3><p>返回一个对象的‘标识’,在一个对象的生命周期中，保持唯一不变。两个不处在同一生命周期的对象调用id()也许会返回一样的值</p><p>CPython实现的细节：返回值是对象在内存中的地址</p><pre><code>&gt;&gt;&gt; s1 = &#39;sss&#39;&gt;&gt;&gt; s2 = &#39;sss&#39;&gt;&gt;&gt; s3 = &#39;s*s&#39;&gt;&gt;&gt; s4 = &#39;s*s&#39;&gt;&gt;&gt; id(s1)4351970960&gt;&gt;&gt; id(s2)4351970960&gt;&gt;&gt; id(s3)4351970640&gt;&gt;&gt; id(s4)4351970680</code></pre><h3 id="input"><a href="#input" class="headerlink" title="input"></a><span id='input'>input</span></h3><h3 id="int"><a href="#int" class="headerlink" title="int"></a><span id='int'>int</span></h3><h3 id="isinstance"><a href="#isinstance" class="headerlink" title="isinstance"></a><span id='isinstance'>isinstance</span></h3><h3 id="issubclass"><a href="#issubclass" class="headerlink" title="issubclass"></a><span id='issubclass'>issubclass</span></h3><h3 id="iter"><a href="#iter" class="headerlink" title="iter"></a><span id='iter'>iter</span></h3><h3 id="len"><a href="#len" class="headerlink" title="len"></a><span id='len'>len</span></h3><h3 id="list"><a href="#list" class="headerlink" title="list"></a><span id='list'>list</span></h3><h3 id="locals"><a href="#locals" class="headerlink" title="locals"></a><span id='locals'>locals</span></h3><h3 id="max"><a href="#max" class="headerlink" title="max"></a><span id='map'>max</span></h3><h3 id="abs"><a href="#abs" class="headerlink" title="abs"></a><span id='max'>abs</span></h3><h3 id="memoryview"><a href="#memoryview" class="headerlink" title="memoryview"></a><span id='memoryview'>memoryview</span></h3><h3 id="min"><a href="#min" class="headerlink" title="min"></a><span id='min'>min</span></h3><h3 id="next"><a href="#next" class="headerlink" title="next"></a><span id='next'>next</span></h3><h3 id="object"><a href="#object" class="headerlink" title="object"></a><span id='object'>object</span></h3><h3 id="oct"><a href="#oct" class="headerlink" title="oct"></a><span id='oct'>oct</span></h3><h3 id="ord"><a href="#ord" class="headerlink" title="ord"></a><span id='open'>ord</span></h3><h3 id="pow"><a href="#pow" class="headerlink" title="pow"></a><span id='pow'>pow</span></h3><h3 id="print-objects-sep-39-39-end-39-n-39-file-sys-stdout-flush-False"><a href="#print-objects-sep-39-39-end-39-n-39-file-sys-stdout-flush-False" class="headerlink" title="print(*objects, sep=&#39; &#39;, end=&#39;\n&#39;, file=sys.stdout, flush=False)"></a><span id='print'><code>print(*objects, sep=&#39; &#39;, end=&#39;\n&#39;, file=sys.stdout, flush=False)</code></span></h3><h3 id="property"><a href="#property" class="headerlink" title="property"></a><span id='property'>property</span></h3><h3 id="range"><a href="#range" class="headerlink" title="range"></a><span id='range'>range</span></h3><h3 id="repr"><a href="#repr" class="headerlink" title="repr"></a><span id='repr'>repr</span></h3><h3 id="reversed"><a href="#reversed" class="headerlink" title="reversed"></a><span id='reversed'>reversed</span></h3><h3 id="round"><a href="#round" class="headerlink" title="round"></a><span id='round'>round</span></h3><h3 id="set"><a href="#set" class="headerlink" title="set"></a><span id='set'>set</span></h3><h3 id="setattr"><a href="#setattr" class="headerlink" title="setattr"></a><span id='setattr'>setattr</span></h3><h3 id="slice"><a href="#slice" class="headerlink" title="slice"></a><span id='slice'>slice</span></h3><h3 id="sorted"><a href="#sorted" class="headerlink" title="sorted"></a><span id='sorted'>sorted</span></h3><h3 id="staticmethod"><a href="#staticmethod" class="headerlink" title="staticmethod"></a><span id='staticmethod'>staticmethod</span></h3><h3 id="str"><a href="#str" class="headerlink" title="str"></a><span id='str'>str</span></h3><h3 id="sum"><a href="#sum" class="headerlink" title="sum"></a><span id='sum'>sum</span></h3><h3 id="super"><a href="#super" class="headerlink" title="super"></a><span id='super'>super</span></h3><h3 id="tuple"><a href="#tuple" class="headerlink" title="tuple"></a><span id='tuple'>tuple</span></h3><h3 id="type"><a href="#type" class="headerlink" title="type"></a><span id='type'>type</span></h3><h3 id="vars"><a href="#vars" class="headerlink" title="vars"></a><span id='vars'>vars</span></h3><h3 id="zip"><a href="#zip" class="headerlink" title="zip"></a><span id='zip'>zip</span></h3><h3 id="import"><a href="#import" class="headerlink" title="__import__"></a><span id='import'><code>__import__</code></span></h3>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> built-in functions </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Install mysql5.7 on aliyun ECS ubuntu16.04.4 </title>
      <link href="/2017/11/07/install-mysql5-7-on-aliyun-ecs-ubuntu16-04-4/"/>
      <url>/2017/11/07/install-mysql5-7-on-aliyun-ecs-ubuntu16-04-4/</url>
      
        <content type="html"><![CDATA[<img src="/img/aliyun.jpg" width="500" height="350"><span id="more"></span><h1 id="阿里云ECS-ubuntu16-04-4-安装MySQL并设置远程访问-以下以root用户操作"><a href="#阿里云ECS-ubuntu16-04-4-安装MySQL并设置远程访问-以下以root用户操作" class="headerlink" title="阿里云ECS(ubuntu16.04.4)安装MySQL并设置远程访问(以下以root用户操作)"></a>阿里云ECS(ubuntu16.04.4)安装MySQL并设置远程访问(以下以root用户操作)</h1><h2 id="更新源"><a href="#更新源" class="headerlink" title="更新源"></a>更新源</h2><pre><code>apt-get update</code></pre><h2 id="安装mysql服务器"><a href="#安装mysql服务器" class="headerlink" title="安装mysql服务器"></a>安装mysql服务器</h2><pre><code>apt-get install mysql-serverapt-get install mysql-clientapt-get install libmysqlclient-dev</code></pre><h2 id="查看是否安装成功-安装之前也可以使用此命令查看是否有安装MySQL"><a href="#查看是否安装成功-安装之前也可以使用此命令查看是否有安装MySQL" class="headerlink" title="查看是否安装成功(安装之前也可以使用此命令查看是否有安装MySQL)"></a>查看是否安装成功(安装之前也可以使用此命令查看是否有安装MySQL)</h2><pre><code>netstat -tap | grep mysql</code></pre><h2 id="重启服务"><a href="#重启服务" class="headerlink" title="重启服务"></a>重启服务</h2><pre><code>/etc/init.d/mysql restart</code></pre><h2 id="登录-假设用户名和密码都为root"><a href="#登录-假设用户名和密码都为root" class="headerlink" title="登录(假设用户名和密码都为root)"></a>登录(假设用户名和密码都为root)</h2><pre><code>mysql -uroot -proot</code></pre><p>正常情况按照以上操作，应该可以进入mysql了。</p><h1 id="远程访问MySQL，阿里云默认只能本地连接，需要以下操作支持远程访问"><a href="#远程访问MySQL，阿里云默认只能本地连接，需要以下操作支持远程访问" class="headerlink" title="远程访问MySQL，阿里云默认只能本地连接，需要以下操作支持远程访问"></a>远程访问MySQL，阿里云默认只能本地连接，需要以下操作支持远程访问</h1><h2 id="数据库安装后"><a href="#数据库安装后" class="headerlink" title="数据库安装后"></a>数据库安装后</h2><ul><li><p>查看数据库</p><p>  mysql&gt; show databases;<br>  +——————–+<br>  | Database           |<br>  +——————–+<br>  | information_schema |<br>  | mysql              |<br>  | performance_schema |<br>  | sys                |<br>  +——————–+<br>  4 rows in set (0.00 sec)</p></li><li><p>切换到mysql库</p><p>  mysql&gt; use mysql;<br>  Reading table information for completion of table and column names<br>  You can turn off this feature to get a quicker startup with -A</p><p>  Database changed</p></li><li><p>查看host,user</p><p>  mysql&gt; select distinct host,user from user;<br>  +———–+——————+<br>  | host      | user             |<br>  +———–+——————+<br>  | localhost | root             |<br>  | localhost | debian-sys-maint |<br>  | localhost | mysql.session    |<br>  | localhost | mysql.sys        |<br>  +———–+——————+<br>  4 rows in set (0.01 sec)</p></li><li><p>更改host以支持远程访问</p><p>  mysql&gt; update user set host=’%’ where user=’root’ and host=’localhost’;</p></li><li><p>刷新权限，使配置生效</p><p>  mysql&gt; flush privileges;</p></li><li><p>一般情况下，到这里就可以远程访问了，但是由于MySQL是安装在阿里云上的，阿里云默认没有开启3306端口，所以需要到阿里云控制台安全组规则配置规则，开启3306端口，默认情况下只有后五条，开启后会多出第一条，如下图</p></li></ul><img src="/img/3306.png" width="500" height="350">]]></content>
      
      
      <categories>
          
          <category> database </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
            <tag> aliyun </tag>
            
            <tag> ubuntu </tag>
            
            <tag> ECS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hello flask 02: hello world</title>
      <link href="/2017/10/30/hello-flask-02-hello-world/"/>
      <url>/2017/10/30/hello-flask-02-hello-world/</url>
      
        <content type="html"><![CDATA[<h1 id="flask系列之Hello-World"><a href="#flask系列之Hello-World" class="headerlink" title="flask系列之Hello World!"></a>flask系列之Hello World!</h1><h3 id="上一篇文章中，已经搭建好了基本环境，这一篇正式进入flask"><a href="#上一篇文章中，已经搭建好了基本环境，这一篇正式进入flask" class="headerlink" title="上一篇文章中，已经搭建好了基本环境，这一篇正式进入flask!"></a>上一篇文章中，已经搭建好了基本环境，这一篇正式进入flask!</h3><h3 id="安装flask"><a href="#安装flask" class="headerlink" title="安装flask"></a>安装flask</h3><pre><code>pip install flask</code></pre><h3 id="查看是否安装成功，pip-freeze显示如下说明安装成功，同时也可以看出flask依赖如下一些包：click-itsdangerous-jinja2-MarkupSafe-Werkzeug-后面会有相关的一些介绍，这里知道就好"><a href="#查看是否安装成功，pip-freeze显示如下说明安装成功，同时也可以看出flask依赖如下一些包：click-itsdangerous-jinja2-MarkupSafe-Werkzeug-后面会有相关的一些介绍，这里知道就好" class="headerlink" title="查看是否安装成功，pip freeze显示如下说明安装成功，同时也可以看出flask依赖如下一些包：click,itsdangerous,jinja2,MarkupSafe,Werkzeug,后面会有相关的一些介绍，这里知道就好"></a>查看是否安装成功，pip freeze显示如下说明安装成功，同时也可以看出flask依赖如下一些包：click,itsdangerous,jinja2,MarkupSafe,Werkzeug,后面会有相关的一些介绍，这里知道就好</h3><pre><code>(micro-blog) jockie:~/programs/learn_flask/flask_microblog (master *)$ pip freezecertifi==2017.7.27.1click==6.7Flask==0.12.2itsdangerous==0.24Jinja2==2.9.6MarkupSafe==1.0Werkzeug==0.12.2</code></pre><span id="more"></span><h3 id="实现flask的hello-world应用，这里我们在官方示例的基础上稍微修改一下"><a href="#实现flask的hello-world应用，这里我们在官方示例的基础上稍微修改一下" class="headerlink" title="实现flask的hello world应用，这里我们在官方示例的基础上稍微修改一下"></a>实现flask的hello world应用，这里我们在官方示例的基础上稍微修改一下</h3><ol><li><p>创建主入口文件app.py</p><pre><code> # coding:utf-8 # 导入Flask类和config配置 from flask import Flask from config import config  # 实例化一个Flask类 app = Flask(__name__)  # 从文件config导入配置，当然在配置项少的情况下也可以直接操作：app.config[&#39;DEBUG&#39;] app.config.from_object(config) # 设置 URL=&#39;/&#39;时的路由规则；以默认GET方法请求访问http://&lt;host:port&gt;/时，调用index(),并将return结果返回给浏览器 @app.route(&#39;/&#39;) def index():     return &#39;&lt;h1&gt;Hello Flask!&lt;/h1&gt;&#39; if __name__ == &#39;__main__&#39;:     # 应用的入口函数     app.run()</code></pre></li><li><p>在app.py中可以看到除了import Flask之外，还import了config文件，config的做用是存放开发所有的一些配置文件，比如在下面创建的config.py中的DEBUG配置，以及后面涉及到的数据库配置等</p><pre><code> # coding:utf-8 # 开启DEBUG模式，便于开发测试，生产环境不建议开启 DEBUG = True</code></pre></li><li><p>运行入口文件app.py文件,程序运行在默认5000端口</p><pre><code> (micro-blog) jockie:~/programs/learn_flask/flask_microblog (master *)$ python app.py  * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)  * Restarting with stat  * Debugger is active!  * Debugger PIN: 210-650-536</code></pre></li><li><p>进入浏览器，查看结果如下</p></li></ol><img src="/img/hello-flask.png" alt="">]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flask </tag>
            
            <tag> web </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hello flask 01: prepare</title>
      <link href="/2017/10/30/hello-flask-01-prepare/"/>
      <url>/2017/10/30/hello-flask-01-prepare/</url>
      
        <content type="html"><![CDATA[<img src="/img/prepare.png" width="500" height="350"><span id="more"></span><h1 id="flask系列之environment"><a href="#flask系列之environment" class="headerlink" title="flask系列之environment"></a>flask系列之environment</h1><h3 id="代码库托管github上，在GitHub上创建一个repository-默认已经安装git-："><a href="#代码库托管github上，在GitHub上创建一个repository-默认已经安装git-：" class="headerlink" title="代码库托管github上，在GitHub上创建一个repository(默认已经安装git)："></a>代码库托管github上，在GitHub上创建一个repository(默认已经安装git)：</h3><ul><li>仓库地址：<a href="https://github.com/keepwonder/flask-microblog.git">https://github.com/keepwonder/flask-microblog.git</a></li><li>创建本地开发目录flask_microblog并和GitHub关联<ol><li>cd /Users/jockie/programs/learn_flask/flask_microblog # 进入项目根目录</li><li>git init # 初始化git仓库</li><li>echo “# Micro Blog with Python Flask” &gt;&gt; README.md # 创建README文件</li><li>git add . # 将新建的README添加进git缓冲</li><li>git commit -m ‘first commit’ # 提交文件至git仓库</li><li>git remote add origin <a href="https://github.com/keepwonder/flask-microblog.git">https://github.com/keepwonder/flask-microblog.git</a> # 添加远程git仓库</li><li>git push -u origin master # 将文件推送至远程git仓库master分支</li></ol></li><li>至此，本地目录已与GitHub仓库关联，以后每次修改本地代码都可以同步推送至GitHub，通过GitHub达到管理跟踪代码的目的</li></ul><h3 id="本地采用虚拟环境隔离这个项目环境，使用conda管理："><a href="#本地采用虚拟环境隔离这个项目环境，使用conda管理：" class="headerlink" title="本地采用虚拟环境隔离这个项目环境，使用conda管理："></a>本地采用虚拟环境隔离这个项目环境，使用conda管理：</h3><ul><li><p>新建一个conda环境<br>  conda create –name micro-blog python=2.7</p></li><li><p>激活micro-blog环境,目录前会显示当前所在环境(micro-blog),以后所有操作，<code>都基于此环境</code><br>  source activate micro-blog<br>  (micro-blog) jockie:~/programs/learn_flask/flask_microblog (master)$</p></li><li><p>在当前环境，运行pip命令，查看相关环境信息,python版本为2.7.14，pip freeze只安装了一个包<br>  (micro-blog) jockie:<del>$ pip list<br>  Package      Version<br>  <code>---------- -----------------</code><br>  certifi    2017.7.27.1<br>  pip        9.0.1<br>  setuptools 36.5.0.post20170921<br>  wheel      0.29.0<br>  (micro-blog) jockie:</del>$ pip freeze<br>  certifi==2017.7.27.1<br>  (micro-blog) jockie:~$ python –version<br>  Python 2.7.14 :: Anaconda, Inc.</p></li><li><p>退出当前虚拟环境<br>  source deactivate</p></li></ul><h3 id="至此，基本环境已经搭建完成，下一步就正式开启项目！"><a href="#至此，基本环境已经搭建完成，下一步就正式开启项目！" class="headerlink" title="至此，基本环境已经搭建完成，下一步就正式开启项目！"></a>至此，基本环境已经搭建完成，下一步就正式开启项目！</h3>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flask </tag>
            
            <tag> web </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>conda cheet sheet</title>
      <link href="/2017/10/26/conda-cheet-sheet/"/>
      <url>/2017/10/26/conda-cheet-sheet/</url>
      
        <content type="html"><![CDATA[<img src="/img/conda.png" width="500" height="350"><span id="more"></span>## Conda basics:<table><thead><tr><th>描述</th><th>命令</th></tr></thead><tbody><tr><td>查看conda是否安装，版本信息</td><td>conda info</td></tr><tr><td>更新conda至最新版本</td><td>conda update conda</td></tr><tr><td>安装Anaconda内置的包</td><td>conda install PACKAGENAME</td></tr><tr><td>运行安装过的包，例如Spyder</td><td>spyder</td></tr><tr><td>更新安装过的程序</td><td>conda update PACKAGENAME</td></tr><tr><td>获取命令行帮助</td><td>COMMANDNAME –help(help前面两个-)<br>例如：conda install –help</td></tr></tbody></table><h2 id="Using-enviroments"><a href="#Using-enviroments" class="headerlink" title="Using enviroments:"></a>Using enviroments:</h2><table><thead><tr><th>描述</th><th>命令</th></tr></thead><tbody><tr><td>创建一个环境，命名为py35，并使用python3.5</td><td>conda create –name py35 python=3.5</td></tr><tr><td>激活并使用新环境</td><td>WINDOWS: activate py35<br>LINUX,MacOS: source py35</td></tr><tr><td>获取所有安装环境列表，当前激活环境以<code>*</code>标记</td><td>conda env list<br>conda info –envs</td></tr><tr><td>完全复制一个环境</td><td>conda create –clone py35 –name py35-2</td></tr><tr><td>列出当前激活环境的所有包和版本信息</td><td>conda list</td></tr><tr><td>列出版本改变历史信息</td><td>conda list –revisions</td></tr><tr><td>将环境恢复至之前的版本</td><td>conda install –revision</td></tr><tr><td>将环境信息保存至文本文件</td><td>conda list –explicit &gt; bio-env.txt</td></tr><tr><td>完全删除一个环境</td><td>conda env remove –name bio-env<br>conda remove –name bio-env –all</td></tr><tr><td>退出当前激活环境</td><td>WINDOWS: deactive<br>macOS, LINUX: source deactive</td></tr><tr><td>从文本文件创建一个环境</td><td>conda env create –file bio-env.txt</td></tr><tr><td>栈命令：创建一个新环境，命名为bio-env，再安装biopython包</td><td>conda create –name bio-env biopython</td></tr></tbody></table><h2 id="Finding-conda-packages"><a href="#Finding-conda-packages" class="headerlink" title="Finding conda packages"></a>Finding conda packages</h2><table><thead><tr><th>描述</th><th>命令</th></tr></thead><tbody><tr><td>使用conda查找一个包</td><td>conda searche PACKAGENAME</td></tr><tr><td>查看Anaconda中的所有包</td><td><a href="https://docs.anaconda.com/anaconda/packages/pkg-docs">https://docs.anaconda.com/anaconda/packages/pkg-docs</a></td></tr></tbody></table><h2 id="Installing-and-updating-packages"><a href="#Installing-and-updating-packages" class="headerlink" title="Installing and updating packages"></a>Installing and updating packages</h2><table><thead><tr><th>描述</th><th>命令</th></tr></thead><tbody><tr><td>安装一个新包(Jupyter Notebook)</td><td>conda install jupter</td></tr><tr><td>运行安装过的包(Jupyter-notebook)</td><td>jupyter-notebook</td></tr><tr><td>在非但前激活环境(bio-env)中安装一个新包(toolz)</td><td>conda install –name bio-env toolz</td></tr><tr><td>更新当前激活环境中的一个包</td><td>conda update scikit-learn</td></tr><tr><td>从指定的渠道(conda-forge)安装一个包(boltons)</td><td>conda install –channel conda-forge boltons</td></tr><tr><td>在当前激活环境使用pip直接从PyPI安装一个包</td><td>pip install boltons</td></tr><tr><td>从指定环境(bio-env)删除一个或多个包(toolz,bltons)</td><td>conda remove –name bio-env toolz boltons</td></tr></tbody></table><h2 id="Managing-multiple-versions-of-Python"><a href="#Managing-multiple-versions-of-Python" class="headerlink" title="Managing multiple versions of Python"></a>Managing multiple versions of Python</h2><table><thead><tr><th>描述</th><th>命令</th></tr></thead><tbody><tr><td>在一个新的名为py34的环境中安装一个不同版本的python</td><td>conda create –name py34 python=3.4</td></tr><tr><td>切换至拥有不同python版本的环境中</td><td>WINDOWS: activate py34<br>LINUX,MacOS: source activate</td></tr><tr><td>显示当前python所在的路径</td><td>WINDOWS: where python<br>LINUX,MacOS: which python</td></tr><tr><td>显示当前python版本信息</td><td>python –version</td></tr></tbody></table><h2 id="Specify-version-numbers"><a href="#Specify-version-numbers" class="headerlink" title="Specify version numbers"></a>Specify version numbers</h2><h3 id="使用conda-create-conda-install命令或者在meta-yaml文件中指定包的版本的方法"><a href="#使用conda-create-conda-install命令或者在meta-yaml文件中指定包的版本的方法" class="headerlink" title="使用conda create,conda install命令或者在meta.yaml文件中指定包的版本的方法"></a>使用<code>conda create</code>,<code>conda install</code>命令或者在<code>meta.yaml</code>文件中指定包的版本的方法</h3><table><thead><tr><th>Constraint type</th><th>Specification</th><th>Result</th></tr></thead><tbody><tr><td>Fuzzy</td><td>numpy=1.11</td><td>1.11.0, 1.11.1, 1.11.2, 1.11.18 etc.</td></tr><tr><td>Exact</td><td>numpy==1.11</td><td>1.11.0</td></tr><tr><td>Greater than or equal to</td><td>“numpy&gt;=1.11”</td><td>1.11.0 or hihger</td></tr><tr><td>OR</td><td>“numpy=1.11.1&#124;1.11.3”</td><td>1.11.1, 1.11.3</td></tr><tr><td>AND</td><td>“numpy&gt;=1.8,&lt;2”</td><td>1.8, 1.9, not 2.0</td></tr></tbody></table><h3 id="notes"><a href="#notes" class="headerlink" title="notes:"></a>notes:</h3><p>markdown表格内换行:<code>&lt;br&gt;</code><br>stack commands:感觉只可意会，翻译成堆栈命令有点奇怪<br>markdown表格转义<code>|</code>:使用ASCII字符集<code>&amp;#124;</code></p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> conda </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>problems in using python</title>
      <link href="/2017/10/25/problems-in-using-python/"/>
      <url>/2017/10/25/problems-in-using-python/</url>
      
        <content type="html"><![CDATA[<img src="/img/problems.jpg" width="500" height="350"><span id="more"></span>(声明，以下Q代表问题，A代表答案)<h2 id="Q1-安装mysql-python库报错，如下："><a href="#Q1-安装mysql-python库报错，如下：" class="headerlink" title="Q1: 安装mysql-python库报错，如下："></a>Q1: 安装mysql-python库报错，如下：</h2><ul><li><p>描述</p><pre><code>  (python27) jockie:/usr/local/bin$ pip install mysql-python  Collecting mysql-python    Using cached MySQL-python-1.2.5.zip      Complete output from command python setup.py egg_info:      sh: mysql_config: command not found      Traceback (most recent call last):        File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;        File &quot;/private/var/folders/yf/m8nhcn4x1vd1snmnykt7n89h0000gn/T/pip-build-sSaKtK/mysql-python/setup.py&quot;, line 17, in &lt;module&gt;          metadata, options = get_config()        File &quot;setup_posix.py&quot;, line 43, in get_config          libs = mysql_config(&quot;libs_r&quot;)        File &quot;setup_posix.py&quot;, line 25, in mysql_config          raise EnvironmentError(&quot;%s not found&quot; % (mysql_config.path,))      EnvironmentError: mysql_config not found      ----------------------------------------  Command &quot;python setup.py egg_info&quot; failed with error code 1 in /private/var/folders/yf/m8nhcn4x1vd1snmnykt7n89h0000gn/T/pip-build-sSaKtK/mysql-python/</code></pre></li><li><p>A1: 找不到mysql_config，原因mysql安装目录/usr/local/mysql/bin不在PATH中,临时解决方法：</p><pre><code>  export PATH=$PATH:/usr/local/mysql/bin</code></pre></li></ul><h2 id="Q2-import循环引用，导致ImportError，"><a href="#Q2-import循环引用，导致ImportError，" class="headerlink" title="Q2: import循环引用，导致ImportError，"></a>Q2: import循环引用，导致ImportError，</h2><ul><li><p>描述：如下两个文件互相调用：</p><pre><code>  #home/__init__.py  from flask import Blueprint  import app.home.views  home = Blueprint(&#39;home&#39;, __name__)    #home/views.py  from . import home  @home.route(&#39;/&#39;)  def index():      return &#39;&lt;h1 style=&quot;color:green&quot;&gt;this is home!&lt;/h1&gt;&#39;  Traceback (most recent call last):    File &quot;/Users/jockie/programs/micro_movie/manage.py&quot;, line 7, in &lt;module&gt;      from app import app    File &quot;/Users/jockie/programs/micro_movie/app/__init__.py&quot;, line 8, in &lt;module&gt;      from app.home import home as home_blueprint    File &quot;/Users/jockie/programs/micro_movie/app/home/__init__.py&quot;, line 9, in &lt;module&gt;      import app.home.views    File &quot;/Users/jockie/programs/micro_movie/app/home/views.py&quot;, line 7, in &lt;module&gt;      from . import home  ImportError: cannot import name &#39;home&#39;</code></pre></li><li><p>A2: 程序执行的顺序是从上往下执行，所以要先定义home对象，再导入视图！修改__init__.py中import顺序</p><pre><code>  #home/__init__.py  from flask import Blueprint  home = Blueprint(&#39;home&#39;, __name__)  import app.home.views</code></pre></li></ul><h2 id="Q3-flask程序中，修改css后，浏览器无法实时显示更新？"><a href="#Q3-flask程序中，修改css后，浏览器无法实时显示更新？" class="headerlink" title="Q3: flask程序中，修改css后，浏览器无法实时显示更新？"></a>Q3: flask程序中，修改css后，浏览器无法实时显示更新？</h2><ul><li>A3: 需要清除浏览器缓存(设置debug=True无效)</li></ul><h2 id="Q4-UnicodeEncodeError-‘ascii’-codec-can’t-encode-character-‘-u3000’-in-position-135-ordinal-not-in-range-128"><a href="#Q4-UnicodeEncodeError-‘ascii’-codec-can’t-encode-character-‘-u3000’-in-position-135-ordinal-not-in-range-128" class="headerlink" title="Q4: UnicodeEncodeError: ‘ascii’ codec can’t encode character ‘\u3000’ in position 135: ordinal not in range(128)"></a>Q4: UnicodeEncodeError: ‘ascii’ codec can’t encode character ‘\u3000’ in position 135: ordinal not in range(128)</h2>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>centos7+hadoop2.8.0 full cluster</title>
      <link href="/2017/09/19/centos7-hadoop2-8-0-full-cluster/"/>
      <url>/2017/09/19/centos7-hadoop2-8-0-full-cluster/</url>
      
        <content type="html"><![CDATA[<img src="/img/hadoop.jpeg" width="500" height="350"><span id="more"></span><h1 id="hadoop完全分布式安装"><a href="#hadoop完全分布式安装" class="headerlink" title="hadoop完全分布式安装"></a>hadoop完全分布式安装</h1><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><ol><li>主机：3台centos7主机，用户名和密码都设置为root/root，hd/hd</li><li>hadoop版本：hadoop2.8.0</li><li>jdk版本：java1.8.0</li></ol><h2 id="配置节点"><a href="#配置节点" class="headerlink" title="配置节点"></a>配置节点</h2><ol><li><p>设置主机ip</p><p> 主机              IP             对应角色<br> master    192.168.140.135       namendoe<br> slave1    192.168.140.136       datanode<br> slave2    192.168.140.137       datanode</p></li><li><p>永久修改hostname 分别设为</p><p> hostnamectl set-hostname  master<br> hostnamectl set-hostname  slave1<br> hostnamectl set-hostname  slave2</p></li><li><p>设置 /etc/hosts文件 ，添加如下</p><p> 192.168.140.135 master<br> 192.168.140.136 slave1<br> 192.168.140.137 slave2</p></li></ol><h2 id="查看java版本-确保java已经安装"><a href="#查看java版本-确保java已经安装" class="headerlink" title="查看java版本,确保java已经安装"></a>查看java版本,确保java已经安装</h2><pre><code>[hd@master bigdata]$ java -versionjava version &quot;1.8.0_131&quot;Java(TM) SE Runtime Environment (build 1.8.0_131-b11)Java HotSpot(TM) 64-Bit Server VM (build 25.131-b11, mixed mode)[hd@master bigdata]$</code></pre><h2 id="关闭防火墙，关闭firewall"><a href="#关闭防火墙，关闭firewall" class="headerlink" title="关闭防火墙，关闭firewall"></a>关闭防火墙，关闭firewall</h2><ol><li><p>查看防火墙状态</p><p> [root@master ~]# firewall-cmd –state<br> running</p></li><li><p>停止服务</p><p> [root@master ~]# systemctl stop firewalld.service<br> [root@master ~]# firewall-cmd –state<br> not running</p></li><li><p>禁用防火墙</p><p> [root@master ~]# systemctl disable firewalld.service<br> Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.<br> Removed symlink /etc/systemd/system/basic.target.wants/firewalld.service.<br> [root@master ~]# firewall-cmd –state<br> not running</p></li></ol><h2 id="hd作为大数据环境用户，给hd用户增加sudo权限"><a href="#hd作为大数据环境用户，给hd用户增加sudo权限" class="headerlink" title="hd作为大数据环境用户，给hd用户增加sudo权限"></a>hd作为大数据环境用户，给hd用户增加sudo权限</h2><pre><code>[root@master ~]# ll /etc/sudoers-r-xr-----. 1 root root 3907 Nov  4  2016 /etc/sudoers[root@master ~]# chmod u+w /etc/sudoers[root@master ~]# vi /etc/sudoers    ## Allow root to run any commands anywhere    root    ALL=(ALL)       ALL    hd      ALL=(ALL)NOPASSWD:ALL[root@master ~]# chmod u-w /etc/sudoers</code></pre><p>切换到hd用户下,配置SSH免密码登录</p><pre><code>ssh-keygen  -t   rsa   -P  &#39;&#39;cp id_rsa.pub authorized_keys</code></pre><h2 id="配置jdk"><a href="#配置jdk" class="headerlink" title="配置jdk"></a>配置jdk</h2><pre><code>[hd@master bigdata]$ sudo vi /etc/profileexport JAVA_HOME=/usr/local/bigdata/jdk1.8export CLASSPATH=$CLASSPATH:$JAVA_HOME/lib/export PATH=$PATH:$JAVA_HOME/bin</code></pre><h2 id="配置Hadoop"><a href="#配置Hadoop" class="headerlink" title="配置Hadoop"></a>配置Hadoop</h2><ol><li><p>编辑hadoop-env.sh</p><pre><code> #The java implementation to use. export JAVA_HOME=/usr/local/bigdata/jdk1.8</code></pre></li><li><p>编辑core-site.xml</p><pre><code> &lt;configuration&gt;     &lt;property&gt;         &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;         &lt;value&gt;/hd/hadoop/tmp&lt;/value&gt;         &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;     &lt;/property&gt;     &lt;property&gt;         &lt;name&gt;fs.default.name&lt;/name&gt;         &lt;value&gt;hdfs://master:9000&lt;/value&gt;     &lt;/property&gt; &lt;/configuration&gt;</code></pre></li><li><p>编辑hdfs-site.xml</p><pre><code> &lt;configuration&gt;     &lt;property&gt;        &lt;name&gt;dfs.name.dir&lt;/name&gt;        &lt;value&gt;/hd/hadoop/dfs/name&lt;/value&gt;        &lt;description&gt;Path on the local filesystem where theNameNode stores the namespace and transactions logs persistently.&lt;/description&gt;     &lt;/property&gt;     &lt;property&gt;        &lt;name&gt;dfs.data.dir&lt;/name&gt;        &lt;value&gt;/hd/hadoop/dfs/data&lt;/value&gt;        &lt;description&gt;Comma separated list of paths on the localfilesystem of a DataNode where it should store its blocks.&lt;/description&gt;     &lt;/property&gt;     &lt;property&gt;        &lt;name&gt;dfs.replication&lt;/name&gt;        &lt;value&gt;2&lt;/value&gt;     &lt;/property&gt;     &lt;property&gt;           &lt;name&gt;dfs.permissions&lt;/name&gt;           &lt;value&gt;false&lt;/value&gt;           &lt;description&gt;need not permissions&lt;/description&gt;     &lt;/property&gt; &lt;/configuration&gt;</code></pre></li><li><p>编辑mapred-site.xml</p><pre><code> &lt;configuration&gt;     &lt;property&gt;         &lt;name&gt;mapred.job.tracker&lt;/name&gt;         &lt;value&gt;master:49001&lt;/value&gt;     &lt;/property&gt;     &lt;property&gt;           &lt;name&gt;mapred.local.dir&lt;/name&gt;            &lt;value&gt;/hd/hadoop/var&lt;/value&gt;     &lt;/property&gt;     &lt;property&gt;            &lt;name&gt;mapreduce.framework.name&lt;/name&gt;            &lt;value&gt;yarn&lt;/value&gt;     &lt;/property&gt; &lt;/configuration&gt;</code></pre></li><li><p>修改hadoop/etc/hadoop/slaves文件，修改如下</p><pre><code> slave1 slave2</code></pre></li><li><p>编辑yarn-site.xml</p><pre><code> &lt;configuration&gt;     &lt;property&gt;         &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;         &lt;value&gt;master&lt;/value&gt;     &lt;/property&gt;     &lt;property&gt;         &lt;description&gt;The address of the applications manager interface in the RM.&lt;/description&gt;         &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;         &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8032&lt;/value&gt;     &lt;/property&gt;     &lt;property&gt;         &lt;description&gt;The address of the scheduler interface.&lt;/description&gt;         &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;         &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8030&lt;/value&gt;     &lt;/property&gt;     &lt;property&gt;         &lt;description&gt;The http address of the RM web application.&lt;/description&gt;         &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;         &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8088&lt;/value&gt;     &lt;/property&gt;     &lt;property&gt;         &lt;description&gt;The https adddress of the RM web application.&lt;/description&gt;         &lt;name&gt;yarn.resourcemanager.webapp.https.address&lt;/name&gt;         &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8090&lt;/value&gt;     &lt;/property&gt;     &lt;property&gt;         &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;         &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8031&lt;/value&gt;     &lt;/property&gt;     &lt;property&gt;         &lt;description&gt;The address of the RM admin interface.&lt;/description&gt;         &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;         &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8033&lt;/value&gt;     &lt;/property&gt;     &lt;property&gt;         &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;         &lt;value&gt;mapreduce_shuffle&lt;/value&gt;     &lt;/property&gt;     &lt;property&gt;         &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;         &lt;value&gt;2048&lt;/value&gt;         &lt;discription&gt;每个节点可用内存,单位MB,默认8182MB&lt;/discription&gt;     &lt;/property&gt;     &lt;property&gt;         &lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;/name&gt;         &lt;value&gt;2.1&lt;/value&gt;     &lt;/property&gt;     &lt;property&gt;         &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;         &lt;value&gt;2048&lt;/value&gt;     &lt;/property&gt;        &lt;property&gt;             &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;             &lt;value&gt;false&lt;/value&gt;     &lt;/property&gt; &lt;/configuration&gt;</code></pre></li></ol>]]></content>
      
      
      <categories>
          
          <category> BigData </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MacOS install scrapy</title>
      <link href="/2017/09/16/macos-install-scrapy/"/>
      <url>/2017/09/16/macos-install-scrapy/</url>
      
        <content type="html"><![CDATA[<img src="/img/scrapy.jpeg" width="500" height="300"><span id="more"></span>## 环境系统版本：macOS Sierra 10.12.6python版本：Python3<h2 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h2><ol><li><p>安装homebrew</p><pre><code> /usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;</code></pre></li><li><p>安装wget</p><pre><code> brew install wget</code></pre></li><li><p>安装command line tools</p><pre><code> xcode-select --install</code></pre></li><li><p>安装pip</p><pre><code> wget https://bootstrap.pypa.io/get-pip.py python get-pip.py</code></pre></li><li><p>重启系统</p><pre><code> 重新启动Mac OS 重启时按住Command+R，进入Recovery模式 在Recovery模式中输入:  csrutil disable; 重新启动，回到Mac OS</code></pre></li><li><p>安装scrapy</p><pre><code> sudo -H pip install Scrapy</code></pre></li><li><p>查看版本信息</p><pre><code> scarpy version</code></pre></li></ol>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> scrapy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>centos7 install mysql5.7</title>
      <link href="/2017/08/27/centos7-install-mysql5-7/"/>
      <url>/2017/08/27/centos7-install-mysql5-7/</url>
      
        <content type="html"><![CDATA[<img src="/img/mysql.jpeg" width="500" height="300"><span id="more"></span>## 卸载系统自带的Mariadb    [root@localhost ~]# rpm -qa | grep mariadb    mariadb-libs-5.5.52-1.el7.x86_64    [root@localhost ~]# rpm -e --nodeps mariadb-libs-5.5.52-1.el7.x86_64    [root@localhost ~]# rpm -qa | grep mariadb    [root@localhost ~]#<h2 id="删除etc目录下的my-cnf文件"><a href="#删除etc目录下的my-cnf文件" class="headerlink" title="删除etc目录下的my.cnf文件"></a>删除etc目录下的my.cnf文件</h2><pre><code>[root@localhost ~]# rm /etc/my.cnfrm: cannot remove ‘/etc/my.cnf’: No such file or directory[root@localhost ~]#</code></pre><h2 id="检查mysql是否存在"><a href="#检查mysql是否存在" class="headerlink" title="检查mysql是否存在"></a>检查mysql是否存在</h2><pre><code>[root@localhost ~]# rpm -qa | grep mysql[root@localhost ~]#</code></pre><h2 id="检查mysql组和用户是否存在，如无创建"><a href="#检查mysql组和用户是否存在，如无创建" class="headerlink" title="检查mysql组和用户是否存在，如无创建"></a>检查mysql组和用户是否存在，如无创建</h2><pre><code>[root@localhost ~]# cat /etc/group | grep mysql[root@localhost ~]# cat /etc/passwd | grep mysql[root@localhost ~]#</code></pre><h2 id="创建mysql用户组"><a href="#创建mysql用户组" class="headerlink" title="创建mysql用户组"></a>创建mysql用户组</h2><pre><code>[root@localhost ~]# groupadd mysql[root@localhost ~]# cat /etc/group | grep mysqlmysql:x:1001:</code></pre><h2 id="创建一个用户名为mysql的用户并加入mysql用户组"><a href="#创建一个用户名为mysql的用户并加入mysql用户组" class="headerlink" title="创建一个用户名为mysql的用户并加入mysql用户组"></a>创建一个用户名为mysql的用户并加入mysql用户组</h2><pre><code>[root@localhost ~]# useradd -g mysql mysql[root@localhost ~]# cat /etc/passwd | grep mysqlmysql:x:1001:1001::/home/mysql:/bin/bash[root@localhost ~]#</code></pre><h2 id="指定password-为-mysql"><a href="#指定password-为-mysql" class="headerlink" title="指定password 为 mysql"></a>指定password 为 mysql</h2><pre><code>[root@localhost ~]# passwd mysqlChanging password for user mysql.New password:BAD PASSWORD: The password is shorter than 8 charactersRetype new password:passwd: all authentication tokens updated successfully.[root@localhost ~]#</code></pre><h2 id="将mysql安装到-usr-local-bigdata下"><a href="#将mysql安装到-usr-local-bigdata下" class="headerlink" title="将mysql安装到/usr/local/bigdata下"></a>将mysql安装到/usr/local/bigdata下</h2><pre><code>[root@localhost bigdata]# lltotal 625636drwxr-xr-x. 10 hd   hd         161 Aug 27 01:24 hadoopdrwxr-xr-x.  8 hd   hd         255 Mar 15 04:35 jdk1.8-rw-r--r--.  1 root root 640650826 Aug 27 05:55 mysql-5.7.19-linux-glibc2.12-x86_64.tar.gz[root@localhost bigdata]# tar -zxf mysql-5.7.19-linux-glibc2.12-x86_64.tar.gz[root@localhost bigdata]# lltotal 625636drwxr-xr-x. 10 hd   hd         161 Aug 27 01:24 hadoopdrwxr-xr-x.  8 hd   hd         255 Mar 15 04:35 jdk1.8drwxr-xr-x.  9 root root       129 Aug 27 05:57 mysql-5.7.19-linux-glibc2.12-x86_64-rw-r--r--.  1 root root 640650826 Aug 27 05:55 mysql-5.7.19-linux-glibc2.12-x86_64.tar.gz[root@localhost bigdata]# mv mysql-5.7.19-linux-glibc2.12-x86_64 mysql57[root@localhost bigdata]# lltotal 625636drwxr-xr-x. 10 hd   hd         161 Aug 27 01:24 hadoopdrwxr-xr-x.  8 hd   hd         255 Mar 15 04:35 jdk1.8drwxr-xr-x.  9 root root       129 Aug 27 05:57 mysql57-rw-r--r--.  1 root root 640650826 Aug 27 05:55 mysql-5.7.19-linux-glibc2.12-x86_64.tar.gz[root@localhost]## 更改所属的组和用户[root@localhost bigdata]# chown -R mysql mysql57/[root@localhost bigdata]# lltotal 0drwxr-xr-x. 10 hd    hd   161 Aug 27 01:24 hadoopdrwxr-xr-x.  8 hd    hd   255 Mar 15 04:35 jdk1.8drwxr-xr-x.  9 mysql root 129 Aug 27 05:57 mysql57[root@localhost bigdata]# chgrp -R mysql mysql57/[root@localhost bigdata]# lltotal 0drwxr-xr-x. 10 hd    hd    161 Aug 27 01:24 hadoopdrwxr-xr-x.  8 hd    hd    255 Mar 15 04:35 jdk1.8drwxr-xr-x.  9 mysql mysql 129 Aug 27 05:57 mysql57root@localhost mysql57]# mkdir data[root@localhost mysql57]# chown -R mysql:mysql data[root@localhost mysql57]# lltotal 36drwxr-xr-x.  2 mysql mysql  4096 Aug 27 05:57 bin-rw-r--r--.  1 mysql mysql 17987 Jun 22 10:13 COPYINGdrwxr-xr-x.  2 mysql mysql     6 Aug 27 06:02 datadrwxr-xr-x.  2 mysql mysql    55 Aug 27 05:57 docsdrwxr-xr-x.  3 mysql mysql  4096 Aug 27 05:57 includedrwxr-xr-x.  5 mysql mysql   229 Aug 27 05:57 libdrwxr-xr-x.  4 mysql mysql    30 Aug 27 05:57 man-rw-r--r--.  1 mysql mysql  2478 Jun 22 10:13 READMEdrwxr-xr-x. 28 mysql mysql  4096 Aug 27 05:57 sharedrwxr-xr-x.  2 mysql mysql    90 Aug 27 05:57 support-files[root@localhost mysql57]#</code></pre><h2 id="在etc下新建配置文件my-cnf，并在该文件内添加以下配置"><a href="#在etc下新建配置文件my-cnf，并在该文件内添加以下配置" class="headerlink" title="在etc下新建配置文件my.cnf，并在该文件内添加以下配置"></a>在etc下新建配置文件my.cnf，并在该文件内添加以下配置</h2><pre><code>[mysql]# 设置mysql客户端默认字符集default-character-set=utf8 [mysqld]skip-name-resolve#设置3306端口port = 3306 # 设置mysql的安装目录basedir=/usr/local/bigdata/mysql57# 设置mysql数据库的数据的存放目录datadir=/usr/local/bigdata/mysql57/data# 允许最大连接数max_connections=200# 服务端使用的字符集默认为8比特编码的latin1字符集character-set-server=utf8# 创建新表时将使用的默认存储引擎default-storage-engine=INNODB lower_case_table_names=1max_allowed_packet=16M</code></pre><h2 id="安装和初始化"><a href="#安装和初始化" class="headerlink" title="安装和初始化"></a>安装和初始化</h2><pre><code>[root@localhost mysql57]# bin/mysql_install_db --user=mysql --basedir=/usr/local/bigdata/mysql57 --datadir=/usr/local/bigdata/mysql57/data/2017-08-27 06:08:18 [WARNING] mysql_install_db is deprecated. Please consider switching to mysqld --initialize2017-08-27 06:08:20 [WARNING] The bootstrap log isn&#39;t empty:2017-08-27 06:08:20 [WARNING] 2017-08-27T10:08:18.703344Z 0 [Warning] --bootstrap is deprecated. Please consider using --initialize instead2017-08-27T10:08:18.705509Z 0 [Warning] Changed limits: max_open_files: 1024 (requested 5000)2017-08-27T10:08:18.705523Z 0 [Warning] Changed limits: table_open_cache: 407 (requested 2000)[root@localhost mysql57]#[root@localhost mysql57]# cp ./support-files/mysql.server /etc/init.d/mysqld[root@localhost mysql57]# chown 777 /etc/my.cnf[root@localhost mysql57]# chmod +x /etc/init.d/mysqld[root@localhost mysql57]# /etc/init.d/mysqld restart ERROR! MySQL server PID file could not be found!Starting MySQL.Logging to &#39;/usr/local/bigdata/mysql57/data/localhost.localdomain.err&#39;. SUCCESS!</code></pre><h2 id="设置开机启动"><a href="#设置开机启动" class="headerlink" title="设置开机启动"></a>设置开机启动</h2><pre><code> [root@localhost mysql57]# chkconfig --level 35 mysqld on [root@localhost mysql57]# chkconfig --list mysqldNote: This output shows SysV services only and does not include native      systemd services. SysV configuration data might be overridden by native      systemd configuration.      If you want to list systemd services use &#39;systemctl list-unit-files&#39;.      To see services enabled on particular target use      &#39;systemctl list-dependencies [target]&#39;.mysqld             0:off    1:off    2:on    3:on    4:on    5:on    6:off[root@localhost mysql57]# chmod +x /etc/rc.d/init.d/mysqld[root@localhost mysql57]# chkconfig --add mysqld[root@localhost mysql57]# chkconfig --list mysqldNote: This output shows SysV services only and does not include native      systemd services. SysV configuration data might be overridden by native      systemd configuration.      If you want to list systemd services use &#39;systemctl list-unit-files&#39;.      To see services enabled on particular target use      &#39;systemctl list-dependencies [target]&#39;.mysqld             0:off    1:off    2:on    3:on    4:on    5:on    6:off[root@localhost mysql57]# service mysqld status SUCCESS! MySQL running (4822)[root@localhost mysql57]#</code></pre><h2 id="设置-etc-profile"><a href="#设置-etc-profile" class="headerlink" title="设置/etc/profile/"></a>设置/etc/profile/</h2><pre><code>export PATH=$PATH:/usr/local/bigdata/mysql557/bin</code></pre><h2 id="获得初始密码"><a href="#获得初始密码" class="headerlink" title="获得初始密码"></a>获得初始密码</h2><pre><code>[root@localhost mysql57]# cat /root/.mysql_secret# Password set for user &#39;root@localhost&#39; at 2017-08-27 06:08:18zm&amp;nSHM5Etpw</code></pre><h2 id="修改密码"><a href="#修改密码" class="headerlink" title="修改密码"></a>修改密码</h2><pre><code>root@localhost mysql57]# mysql -uroot -pEnter password:Welcome to the MySQL monitor.  Commands end with ; or \g.Your MySQL connection id is 4Server version: 5.7.19Copyright (c) 2000, 2017, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &#39;help;&#39; or &#39;\h&#39; for help. Type &#39;\c&#39; to clear the current input statement.mysql&gt; set PASSWORD = PASSWORD(&#39;root&#39;)    -&gt; ;Query OK, 0 rows affected, 1 warning (0.01 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec)mysql&gt;</code></pre><h2 id="添加远程访问权限"><a href="#添加远程访问权限" class="headerlink" title="添加远程访问权限"></a>添加远程访问权限</h2><pre><code>mysql&gt; use mysqlReading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; update user set host=&#39;%&#39; where user=&#39;root&#39;;Query OK, 1 row affected (0.00 sec)Rows matched: 1  Changed: 1  Warnings: 0mysql&gt; select host,user from user;+-----------+---------------+| host      | user          |+-----------+---------------+| %         | root          || localhost | mysql.session || localhost | mysql.sys     |+-----------+---------------+3 rows in set (0.00 sec)</code></pre><h2 id="重启生效"><a href="#重启生效" class="headerlink" title="重启生效"></a>重启生效</h2><pre><code>[root@localhost mysql57]# systemctl restart mysql.service[root@localhost mysql57]# /etc/init.d/mysqld restartShutting down MySQL.. SUCCESS!Starting MySQL. SUCCESS!</code></pre><h2 id="为了在任何目录下可以登录mysql"><a href="#为了在任何目录下可以登录mysql" class="headerlink" title="为了在任何目录下可以登录mysql"></a>为了在任何目录下可以登录mysql</h2><pre><code>[root@localhost mysql57]# ln -s /usr/local/bigdata/mysql57/bin/mysql   /usr/bin/mysql</code></pre>]]></content>
      
      
      <categories>
          
          <category> BigData </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql5.7 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu16.04 Install and Configure HBase</title>
      <link href="/2017/08/19/ubuntu16-04-install-and-configure-hbase/"/>
      <url>/2017/08/19/ubuntu16-04-install-and-configure-hbase/</url>
      
        <content type="html"><![CDATA[<img src="/img/hbase.jpg" width="500" height="300"><span id="more"></span><h2 id="HBase安装"><a href="#HBase安装" class="headerlink" title="HBase安装"></a>HBase安装</h2><ol><li><p>下载安装包<br>从HBase<a href="http://mirror.bit.edu.cn/apache/hbase/stable">官网</a>下载最新稳定版，目前为hbase-1.2.6-bin.tar.gz</p></li><li><p>解压安装包<br>将安装包解压至/usr/local目录下，并重命名为hbase,并给hbase目录用户和所属组都改为hadoop</p><pre><code> hadoop@ubuntu16:/usr/local$ sudo chown -R hadoop:hadoop hbase hadoop@ubuntu16:/usr/local$ ll | grep hbase drwxrwxr-x  9 hadoop hadoop  4096 8月  19 19:59 hbase/ hadoop@ubuntu16:/usr/local$ cd hbase/ hadoop@ubuntu16:/usr/local/hbase$ ll total 356 drwxrwxr-x  9 hadoop hadoop   4096 8月  19 19:59 ./ drwxr-xr-x 15 root   root     4096 8月  19 19:42 ../ drwxr-xr-x  4 hadoop hadoop   4096 1月  29  2016 bin/ -rw-r--r--  1 hadoop hadoop 129552 5月  29 14:29 CHANGES.txt drwxr-xr-x  2 hadoop hadoop   4096 8月  19 19:58 conf/ drwxr-xr-x 12 hadoop hadoop   4096 5月  29 15:20 docs/ drwxrwxr-x  7 hadoop hadoop   4096 8月  19 19:59 hbase-tmp/ drwxr-xr-x  7 hadoop hadoop   4096 5月  29 14:53 hbase-webapps/ -rw-rw-r--  1 hadoop hadoop    261 5月  29 15:31 LEGAL drwxrwxr-x  3 hadoop hadoop   4096 8月  19 19:41 lib/ -rw-rw-r--  1 hadoop hadoop 143082 5月  29 15:31 LICENSE.txt drwxrwxr-x  2 hadoop hadoop   4096 8月  19 19:59 logs/ -rw-rw-r--  1 hadoop hadoop  42115 5月  29 15:31 NOTICE.txt -rw-r--r--  1 hadoop hadoop   1477 12月 27  2015 README.txt</code></pre></li><li><p>配置安装路径<br>修改hadoop用户下.bashrc文件，添加如下:</p><pre><code> export HBASE_HOME=/usr/local/hbase export PATH=$PATH:$HBASE_HOME/bin:$PATH</code></pre><p>执行source命令使修改生效:</p><pre><code> hadoop@ubuntu16:~$ source .bashrc</code></pre></li><li><p>验证安装是否成功</p><pre><code> hadoop@ubuntu16:~$ hbase version HBase 1.2.6 Source code repository file:///home/busbey/projects/hbase/hbase-assembly/target/hbase-1.2.6 revision=Unknown Compiled by busbey on Mon May 29 02:25:32 CDT 2017 From source with checksum 7e8ce83a648e252758e9dae1fbe779c9</code></pre><p> 看到以上消息表示hbase成功安装。</p></li></ol><h2 id="HBase单机模式"><a href="#HBase单机模式" class="headerlink" title="HBase单机模式"></a>HBase单机模式</h2><ol><li><p>配置/conf/hbase-env.sh<br>配置JAVA_HOME和HBASE_MANAGES_ZK两个变量</p><pre><code> export JAVA_HOME=/home/johnathon/Java/jdk1.8.0_131 export HBASE_MANAGES_ZK=true</code></pre></li><li><p>配置/conf/hbase-site.xml<br>在启动Hbase前需要设置属性hbase.rootdir，用于指定Hbase数据的存储位置，此处设置为HBase安装目录下的hbase-tmp文件夹即（file:///usr/local/hbase/hbase-tmp），配置如下：</p><pre><code> &lt;configuration&gt;          &lt;property&gt;                  &lt;name&gt;hbase.rootdir&lt;/name&gt;                  &lt;value&gt;file:///usr/local/hbase/hbase-tmp&lt;/value&gt;          &lt;/property&gt; &lt;/configuration&gt;</code></pre></li><li><p>启动HBase<br> 启动之前先jps查看下，这里hadoop已经运行，hbase单机模式可以不开启hadoop</p><pre><code> hadoop@ubuntu16:/usr/local/hbase/conf$ jps 16913 RunJar 14580 NodeManager 18182 Jps 14935 JobHistoryServer 14105 DataNode 14459 ResourceManager 14302 SecondaryNameNode 13951 NameNode</code></pre><p> 使用start-hbase.sh脚本启动hbase</p><pre><code> hadoop@ubuntu16:/usr/local/hbase/conf$ start-hbase.sh starting master, logging to /usr/local/hbase/logs/hbase-hadoop-master-ubuntu16.out</code></pre><p> 再jps查看下,多出个HMaster进程</p><pre><code> hadoop@ubuntu16:/usr/local/hbase/conf$ jps 16913 RunJar 18307 HMaster 14580 NodeManager 14935 JobHistoryServer 18615 Jps 14105 DataNode 14459 ResourceManager 14302 SecondaryNameNode 13951 NameNode hadoop@ubuntu16:/usr/local/hbase/conf$ jps | grep HM 18307 HMaster</code></pre></li><li><p>进入hbase shell<br> 进入shell模式之后，通过status命令查看运行状态，通过exit退出shell</p><pre><code> hadoop@ubuntu16:/usr/local/hbase/conf$ hbase shell SLF4J: Class path contains multiple SLF4J bindings. SLF4J: Found binding in [jar:file:/usr/local/hbase/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation. SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory] HBase Shell; enter &#39;help&lt;RETURN&gt;&#39; for list of supported commands. Type &quot;exit&lt;RETURN&gt;&quot; to leave the HBase Shell Version 1.2.6, rUnknown, Mon May 29 02:25:32 CDT 2017 hbase(main):001:0&gt; status 1 active master, 0 backup masters, 1 servers, 0 dead, 2.0000 average load hbase(main):002:0&gt; exit hadoop@ubuntu16:/usr/local/hbase/conf$</code></pre></li><li><p>停止HBase</p><pre><code> hadoop@ubuntu16:/usr/local/hbase/conf$ stop-hbase.sh stopping hbase................. hadoop@ubuntu16:/usr/local/hbase/conf$</code></pre></li></ol><h2 id="HBase伪分布式"><a href="#HBase伪分布式" class="headerlink" title="HBase伪分布式"></a>HBase伪分布式</h2><ol><li><p>配置/conf/hbase-env.sh<br>添加如下</p><pre><code> export HBASE_CLASSPATH=/usr/local/hadoop/conf</code></pre></li><li><p>配置/conf/hbase-site.xml<br>修改hbase.rootdir，将其指向localhost(与hdfs的端口保持一致)，并指定HBase在HDFS上的存储路径。将属性hbase.cluter.distributed设置为true。假设当前Hadoop集群运行在伪分布式模式下，且NameNode运行在9000端口；</p><pre><code> &lt;configuration&gt;     &lt;property&gt;         &lt;name&gt;hbase.rootdir&lt;/name&gt;         &lt;value&gt;hdfs://localhost:9000/hbase&lt;/value&gt;     &lt;/property&gt;     &lt;property&gt;         &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;         &lt;value&gt;true&lt;/value&gt;     &lt;/property&gt; &lt;/configuration&gt;</code></pre></li><li><p>启动HBase<br> 启动之前，保证hadoop已经启动，可用jps查看进程</p><pre><code> hadoop@ubuntu16:/usr/local/hbase/conf$ start-hbase.sh localhost: starting zookeeper, logging to /usr/local/hbase/bin/../logs/hbase-hadoop-zookeeper-ubuntu16.out starting master, logging to /usr/local/hbase/logs/hbase-hadoop-master-ubuntu16.out starting regionserver, logging to /usr/local/hbase/logs/hbase-hadoop-1-regionserver-ubuntu16.out</code></pre><p> jps查看进程</p><pre><code> hadoop@ubuntu16:/usr/local/hbase/conf$ jps 16913 RunJar 14580 NodeManager 23094 HQuorumPeer 14935 JobHistoryServer 23287 HRegionServer 23160 HMaster 23880 Jps 14105 DataNode 14459 ResourceManager 14302 SecondaryNameNode 13951 NameNode</code></pre><p> 再过滤下，可看出多出如下3个进程</p><pre><code> hadoop@ubuntu16:/usr/local/hbase/conf$ jps | awk &#39;&#123;print $2&#125;&#39;| grep &#39;^H&#39; HQuorumPeer HRegionServer HMaster</code></pre></li><li><p>进程shell模式<br>进入shell模式之后，通过list命令查看当前数据库所有表信息，通过create命令创建一个employee表，其拥有employee_id,address,info三个列族，通过describe命令查看employee表结构，通过exit命令退出HBase shell模式。</p><pre><code> hadoop@ubuntu16:/usr/local/hbase/conf$ hbase shell SLF4J: Class path contains multiple SLF4J bindings. SLF4J: Found binding in [jar:file:/usr/local/hbase/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation. SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory] HBase Shell; enter &#39;help&lt;RETURN&gt;&#39; for list of supported commands. Type &quot;exit&lt;RETURN&gt;&quot; to leave the HBase Shell Version 1.2.6, rUnknown, Mon May 29 02:25:32 CDT 2017 hbase(main):001:0&gt; create &#39;employee&#39;,&#39;employee_id&#39;,&#39;address&#39;,&#39;info&#39; 0 row(s) in 1.8040 seconds =&gt; Hbase::Table - employee hbase(main):006:0&gt; list TABLE employee 1 row(s) in 0.0080 seconds =&gt; [&quot;employee&quot;] hbase(main):007:0&gt; describe &#39;employee&#39; Table employee is ENABLED employee COLUMN FAMILIES DESCRIPTION &#123;NAME =&gt; &#39;address&#39;, BLOOMFILTER =&gt; &#39;ROW&#39;, VERSIONS =&gt; &#39;1&#39;, IN_MEMORY =&gt; &#39;false&#39;,  KEEP_DELETED_CELLS =&gt; &#39;FALSE&#39;, DATA_BLOCK_ENCODING =&gt; &#39;NONE&#39;, TTL =&gt; &#39;FOREVER&#39;,  COMPRESSION =&gt; &#39;NONE&#39;, MIN_VERSIONS =&gt; &#39;0&#39;, BLOCKCACHE =&gt; &#39;true&#39;, BLOCKSIZE =&gt; &#39;65536&#39;, REPLICATION_SCOPE =&gt; &#39;0&#39;&#125; &#123;NAME =&gt; &#39;employee_id&#39;, BLOOMFILTER =&gt; &#39;ROW&#39;, VERSIONS =&gt; &#39;1&#39;, IN_MEMORY =&gt; &#39;fal se&#39;, KEEP_DELETED_CELLS =&gt; &#39;FALSE&#39;, DATA_BLOCK_ENCODING =&gt; &#39;NONE&#39;, TTL =&gt; &#39;FOREV ER&#39;, COMPRESSION =&gt; &#39;NONE&#39;, MIN_VERSIONS =&gt; &#39;0&#39;, BLOCKCACHE =&gt; &#39;true&#39;, BLOCKSIZE  =&gt; &#39;65536&#39;, REPLICATION_SCOPE =&gt; &#39;0&#39;&#125; &#123;NAME =&gt; &#39;info&#39;, BLOOMFILTER =&gt; &#39;ROW&#39;, VERSIONS =&gt; &#39;1&#39;, IN_MEMORY =&gt; &#39;false&#39;, KE EP_DELETED_CELLS =&gt; &#39;FALSE&#39;, DATA_BLOCK_ENCODING =&gt; &#39;NONE&#39;, TTL =&gt; &#39;FOREVER&#39;, CO MPRESSION =&gt; &#39;NONE&#39;, MIN_VERSIONS =&gt; &#39;0&#39;, BLOCKCACHE =&gt; &#39;true&#39;, BLOCKSIZE =&gt; &#39;65 536&#39;, REPLICATION_SCOPE =&gt; &#39;0&#39;&#125; 3 row(s) in 0.0650 seconds hbase(main):008:0&gt; exit hadoop@ubuntu16:/usr/local/hbase/conf$</code></pre></li><li><p>查看HDFS的HBase数据库文件<br>通过hdfs dfs –ls /hbase命令查看HBase分布式数据库在HDFS上是否成功创建，/hbase/data/default/employee文件夹即为上一步我们所建立的employee在HDFS上的存储位置。</p><pre><code> hadoop@ubuntu16:/usr/local/hbase/conf$ hdfs dfs -ls /hbase Found 8 items drwxr-xr-x   - hadoop supergroup          0 2017-08-19 21:36 /hbase/.tmp drwxr-xr-x   - hadoop supergroup          0 2017-08-19 21:36 /hbase/MasterProcWALs drwxr-xr-x   - hadoop supergroup          0 2017-08-19 21:26 /hbase/WALs drwxr-xr-x   - hadoop supergroup          0 2017-08-19 21:38 /hbase/archive drwxr-xr-x   - hadoop supergroup          0 2017-08-19 21:10 /hbase/data -rw-r--r--   1 hadoop supergroup         42 2017-08-19 21:10 /hbase/hbase.id -rw-r--r--   1 hadoop supergroup          7 2017-08-19 21:10 /hbase/hbase.version drwxr-xr-x   - hadoop supergroup          0 2017-08-19 21:36 /hbase/oldWALs hadoop@ubuntu16:/usr/local/hbase/conf$ hdfs dfs -ls /hbase/data/default Found 1 items drwxr-xr-x   - hadoop supergroup          0 2017-08-19 21:36 /hbase/data/default/employee</code></pre></li><li><p>通过界面查看相关信息<br>主机ip:50070查看hdfs信息,如下图</p><img src="/img/hbase_01.jpg">主机ip:16010查看hbase相关新，如下图<img src="/img/hbase_02.jpg"></li><li><p>停止HBase</p><pre><code> hadoop@ubuntu16:/usr/local/hbase/conf$ stop-hbase.sh stopping hbase................... localhost: stopping zookeeper. hadoop@ubuntu16:/usr/local/hbase/conf$</code></pre></li></ol>]]></content>
      
      
      <categories>
          
          <category> BigData </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hbase </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>whois</title>
      <link href="/2017/08/05/python-whois/"/>
      <url>/2017/08/05/python-whois/</url>
      
        <content type="html"><![CDATA[<img src="/img/whois.jpeg" width="500" height="350"><span id="more"></span><h4 id="在爬取一个网站时，又是我们需要查看一个网站的所有者相关信息，这时就可以用到whois这个模块"><a href="#在爬取一个网站时，又是我们需要查看一个网站的所有者相关信息，这时就可以用到whois这个模块" class="headerlink" title="在爬取一个网站时，又是我们需要查看一个网站的所有者相关信息，这时就可以用到whois这个模块"></a>在爬取一个网站时，又是我们需要查看一个网站的所有者相关信息，这时就可以用到whois这个模块</h4><h2 id="step1-使用pip-install-python-whois安装whois模块"><a href="#step1-使用pip-install-python-whois安装whois模块" class="headerlink" title="step1: 使用pip install python-whois安装whois模块"></a>step1: 使用pip install python-whois安装whois模块</h2><pre><code>(/Users/jockie/install_programs/anaconda) jockie:~/programs/pycharm$ pip install python-whoisCollecting python-whois  Downloading python-whois-0.6.5.tar.gzCollecting future (from python-whois)  Downloading future-0.16.0.tar.gz (824kB)    100% |################################| 829kB 137kB/s Building wheels for collected packages: python-whois, future  Running setup.py bdist_wheel for python-whois ... done  Stored in directory: /Users/jockie/Library/Caches/pip/wheels/37/68/27/819a3f07cbe75200d8cfa74d4517fd0f402b6dd7aaf91afe8b  Running setup.py bdist_wheel for future ... done  Stored in directory: /Users/jockie/Library/Caches/pip/wheels/c2/50/7c/0d83b4baac4f63ff7a765bd16390d2ab43c93587fac9d6017aSuccessfully built python-whois futureInstalling collected packages: future, python-whoisSuccessfully installed future-0.16.0 python-whois-0.6.5</code></pre><h2 id="step2-使用whois"><a href="#step2-使用whois" class="headerlink" title="step2: 使用whois"></a>step2: 使用whois</h2><pre><code>In [1]: import whoisIn [2]: whois.whois(&#39;xuanxiewu.com&#39;)Out[2]: &#123;&#39;address&#39;: &#39;NanJingShiYuHuaTaiQuXiShanQiaoMeiXinXiaoQu&#39;, &#39;city&#39;: &#39;Nanjing&#39;, &#39;country&#39;: &#39;CN&#39;, &#39;creation_date&#39;: datetime.datetime(2014, 9, 28, 4, 9, 31), &#39;dnssec&#39;: &#39;unsigned&#39;, &#39;domain_name&#39;: [&#39;XUANXIEWU.COM&#39;, &#39;xuanxiewu.com&#39;], &#39;emails&#39;: [&#39;tld@cndns.com&#39;, &#39;domain@cndns.com&#39;, &#39;1044699649@qq.com&#39;], &#39;expiration_date&#39;: [datetime.datetime(2018, 9, 28, 4, 9, 31),  datetime.datetime(2018, 9, 28, 12, 7, 1)], &#39;name&#39;: &#39;qiang jiong&#39;, &#39;name_servers&#39;: [&#39;F1G1NS1.DNSPOD.NET&#39;,  &#39;F1G1NS2.DNSPOD.NET&#39;,  &#39;f1g1ns1.dnspod.net&#39;,  &#39;f1g1ns2.dnspod.net&#39;], &#39;org&#39;: &#39;qiang jiong&#39;, &#39;referral_url&#39;: None, &#39;registrar&#39;: &#39;SHANGHAI MEICHENG TECHNOLOGY INFORMATION DEVELOPMENT CO., LTD.&#39;, &#39;state&#39;: &#39;Jiangsu&#39;, &#39;status&#39;: [&#39;clientTransferProhibited https://icann.org/epp#clientTransferProhibited&#39;,  &#39;ok https://icann.org/epp#ok&#39;], &#39;updated_date&#39;: [datetime.datetime(2017, 6, 19, 15, 33, 50),  datetime.datetime(2017, 6, 19, 23, 33, 51)], &#39;whois_server&#39;: &#39;grs-whois.cndns.com&#39;, &#39;zipcode&#39;: &#39;210041&#39;&#125;</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> spider </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Use builtwith in python3</title>
      <link href="/2017/08/05/use-builtwith-in-python3/"/>
      <url>/2017/08/05/use-builtwith-in-python3/</url>
      
        <content type="html"><![CDATA[<img src="/img/builtwith.jpeg" width="500" height="350"><span id="more"></span><h2 id="python3中使用builtwith模块（使用工具pycharm-命令行也是pycharm自带terminal）"><a href="#python3中使用builtwith模块（使用工具pycharm-命令行也是pycharm自带terminal）" class="headerlink" title="python3中使用builtwith模块（使用工具pycharm,命令行也是pycharm自带terminal）"></a>python3中使用builtwith模块（使用工具pycharm,命令行也是pycharm自带terminal）</h2><h3 id="step1-使用pip-install-builtwith-来安装builtwith模块"><a href="#step1-使用pip-install-builtwith-来安装builtwith模块" class="headerlink" title="step1: 使用pip install builtwith 来安装builtwith模块"></a>step1: 使用pip install builtwith 来安装builtwith模块</h3><pre><code>    (/Users/jockie/install_programs/anaconda) jockie:~/programs/pycharm$ pip install builtwith    Collecting builtwith      Downloading builtwith-1.3.2.tar.gz    Building wheels for collected packages: builtwith      Running setup.py bdist_wheel for builtwith ... done      Stored in directory: /Users/jockie/Library/Caches/pip/wheels/e4/cf/86/aa813feb4c79e680590a42766642b130358a01f1e26ecfe1d6    Successfully built builtwith    Installing collected packages: builtwith    Successfully installed builtwith-1.3.2</code></pre><h3 id="step2-测试builtwith模块"><a href="#step2-测试builtwith模块" class="headerlink" title="step2: 测试builtwith模块"></a>step2: 测试builtwith模块</h3><pre><code>    import builtwith    info = builtwith.parse(&#39;http://www.xuanxiewu.com&#39;)    print(info)</code></pre><p>运行代码报如下错误</p><pre><code>    /Users/jockie/install_programs/anaconda/bin/python.app /Users/jockie/programs/pycharm/python_spider/chp01_01.py    Traceback (most recent call last):      File &quot;/Users/jockie/programs/pycharm/python_spider/chp01_01.py&quot;, line 8, in &lt;module&gt;        import builtwith      File &quot;/Users/jockie/install_programs/anaconda/lib/python3.6/site-packages/builtwith/__init__.py&quot;, line 42        except Exception , e:                         ^    SyntaxError: invalid syntax    Process finished with exit code 1</code></pre><p>可以看出报的是语法错误，那为什么会有语法错误呢？原因是builtwith是基于python2.x版本的，所以这里需要做一些相应的语法修改<br>1.python2的‘Exception , e’写法不支持， 修改为Exception as e<br>2.python2的print表达式，修改为print()函数<br>3.builtwith使用的urllib2模块属于python2，python3中使用urllib,所以在__init__.py源码中使用urllib2的地方都需要改urllib的写法，首先需要将 import urllib2替换成</p><pre><code>    import urllib.request    import urllib.error</code></pre><p>再将urllib2相关方法替换</p><pre><code>    request = urllib.request.Request(url, None, &#123;&#39;User-Agent&#39;: user_agent&#125;)    # request = urllib2.Request(url, None, &#123;&#39;User-Agent&#39;: user_agent&#125;)    response = urllib.request.urlopen(request)    # response = urllib2.urlopen(request)</code></pre><p>再次运行代码,报如下错误：</p><pre><code>    /Users/jockie/install_programs/anaconda/bin/python.app /Users/jockie/programs/pycharm/python_spider/chp01_01.py    Traceback (most recent call last):      File &quot;/Users/jockie/programs/pycharm/python_spider/chp01_01.py&quot;, line 10, in &lt;module&gt;        info = builtwith.parse(&#39;http://www.baidu.com&#39;)      File &quot;/Users/jockie/install_programs/anaconda/lib/python3.6/site-packages/builtwith/__init__.py&quot;, line 69, in builtwith        if contains(html, snippet):      File &quot;/Users/jockie/install_programs/anaconda/lib/python3.6/site-packages/builtwith/__init__.py&quot;, line 111, in contains        return re.compile(regex.split(&#39;\\;&#39;)[0], flags=re.IGNORECASE).search(v)    TypeError: cannot use a string pattern on a bytes-like object    Process finished with exit code 1</code></pre><p>可以看出报的是类型错误，这是因为urllib返回的数据格式已经发生了改变，需要进行转码，将下面的代码</p><pre><code>    if html is None:          html = response.read() </code></pre><p>改为</p><pre><code>    if html is None:           html = response.read()           html = html.decode(&#39;utf-8&#39;)</code></pre><p>再次运行代码，得到正确结果</p><pre><code>    /Users/jockie/install_programs/anaconda/bin/python.app /Users/jockie/programs/pycharm/python_spider/chp01_01.py    &#123;&#39;font-scripts&#39;: [&#39;Font Awesome&#39;, &#39;Google Font API&#39;], &#39;web-frameworks&#39;: [&#39;Twitter Bootstrap&#39;], &#39;javascript-frameworks&#39;: [&#39;jQuery&#39;]&#125;    Process finished with exit code 0</code></pre><p>但是，再看上面的解码使用的是utf-8，写死了，如果网站用的不是utf-8呢，这里再试验下，以<a href="http://www.163.com为例,使用的是gbk,再次运行,又报如下错误/">www.163.com为例，使用的是gbk,再次运行，又报如下错误</a></p><pre><code>    /Users/jockie/install_programs/anaconda/bin/python.app /Users/jockie/programs/pycharm/python_spider/chp01_01.py    Error: &#39;utf-8&#39; codec can&#39;t decode byte 0xcd in position 565: invalid continuation byte    Traceback (most recent call last):      File &quot;/Users/jockie/programs/pycharm/python_spider/chp01_01.py&quot;, line 10, in &lt;module&gt;        info = builtwith.parse(&#39;http://www.163.com&#39;)      File &quot;/Users/jockie/install_programs/anaconda/lib/python3.6/site-packages/builtwith/__init__.py&quot;, line 69, in builtwith        if contains(html, snippet):      File &quot;/Users/jockie/install_programs/anaconda/lib/python3.6/site-packages/builtwith/__init__.py&quot;, line 111, in contains        return re.compile(regex.split(&#39;\\;&#39;)[0], flags=re.IGNORECASE).search(v)    TypeError: cannot use a string pattern on a bytes-like object    Process finished with exit code 1</code></pre><p>将编码改为gbk，得到正确结果</p><pre><code>    /Users/jockie/install_programs/anaconda/bin/python.app /Users/jockie/programs/pycharm/python_spider/chp01_01.py    &#123;&#39;web-servers&#39;: [&#39;Nginx&#39;]&#125;    Process finished with exit code 0</code></pre><p>那么问题来了，不同的网站编码不一定相同，如果每次换一个网站，就要改一遍编码的话，那将增加许多额外的工作量，也是不现实的，那么有没有方法做到一劳永逸呢，这里就需要引入chardet模块,同样使用：pip install chardet,将builtwith源码，做如下修改</p><pre><code>        if html is None:            html = response.read()            # html = html.decode(&#39;utf-8&#39;)  # add by Johnahton 20170805            encode_type = chardet.detect(html)            if encode_type[&#39;encoding&#39;] == &#39;utf-8&#39;:                html = html.decode(&#39;utf-8&#39;)            else:                html = html.decode(&#39;gbk&#39;)</code></pre><p> 加入chardet判断字符编码后，就可以一劳永逸了！</p>]]></content>
      
      
      <categories>
          
          <category> DataAnalysis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> spider </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu16.04 Install Git</title>
      <link href="/2017/07/22/ubuntu16-04-install-git/"/>
      <url>/2017/07/22/ubuntu16-04-install-git/</url>
      
        <content type="html"><![CDATA[<img src="/img/git.jpg" width="500" height="350"><span id="more"></span>## 安装Gitubuntu系统安装软件一般直接apt-get install就OK了,所以可以直接用: -         johnathon@ubuntu16:~$ sudo apt-get install git查看版本：-         johnathon@ubuntu16:~$ git --version        git version 2.7.4<p>当前最新版本并不是2.7.4，而是2.13.3，所以直接这样安装的话并不能安装最新的git版本，正确的步骤按照以下进行</p><ol><li><p>sudo add-apt-repository ppa:git-core/ppa</p><pre><code> johnathon@ubuntu16ohnathon@ubuntu16:~$ sudo add-apt-repository ppa:git-core/ppa  The most current stable version of Git for Ubuntu. For release candidates, go to https://launchpad.net/~git-core/+archive/candidate .  More info: https://launchpad.net/~git-core/+archive/ubuntu/ppa Press [ENTER] to continue or ctrl-c to cancel adding it gpg: keyring `/tmp/tmpbb9o0lni/secring.gpg&#39; created gpg: keyring `/tmp/tmpbb9o0lni/pubring.gpg&#39; created gpg: requesting key E1DF1F24 from hkp server keyserver.ubuntu.com gpg: /tmp/tmpbb9o0lni/trustdb.gpg: trustdb created gpg: key E1DF1F24: public key &quot;Launchpad PPA for Ubuntu Git Maintainers&quot; imported gpg: Total number processed: 1 gpg:               imported: 1  (RSA: 1) OK</code></pre></li><li><p>更新软件源，sudo apt-get update</p><pre><code> johnathon@ubuntu16:~$ sudo apt-get update Hit:1 http://cn.archive.ubuntu.com/ubuntu xenial InRelease Hit:2 http://cn.archive.ubuntu.com/ubuntu xenial-updates InRelease Hit:3 http://cn.archive.ubuntu.com/ubuntu xenial-backports InRelease Get:4 http://ppa.launchpad.net/git-core/ppa/ubuntu xenial InRelease [17.5 kB] Hit:5 http://security.ubuntu.com/ubuntu xenial-security InRelease Get:6 http://ppa.launchpad.net/git-core/ppa/ubuntu xenial/main amd64 Packages [3256 B] Get:7 http://ppa.launchpad.net/git-core/ppa/ubuntu xenial/main i386 Packages [3248 B] Get:8 http://ppa.launchpad.net/git-core/ppa/ubuntu xenial/main Translation-en [2496 B] Fetched 26.5 kB in 1s (13.7 kB/s) Reading package lists... Done</code></pre></li><li><p>安装git，sudo apt-get install git</p><pre><code> johnathon@ubuntu16:~$ sudo apt-get install git Reading package lists... Done Building dependency tree Reading state information... Done The following packages were automatically installed and are no longer required:   linux-headers-4.8.0-36 linux-headers-4.8.0-36-generic   linux-image-4.8.0-36-generic linux-image-extra-4.8.0-36-generic Use &#39;sudo apt autoremove&#39; to remove them. The following additional packages will be installed:   git-man Suggested packages:   git-daemon-run | git-daemon-sysvinit git-doc git-el git-email git-gui gitk   gitweb git-arch git-cvs git-mediawiki git-svn The following NEW packages will be installed:   git The following packages will be upgraded:   git-man 1 upgraded, 1 newly installed, 0 to remove and 129 not upgraded. Need to get 6174 kB of archives. After this operation, 30.4 MB of additional disk space will be used. Do you want to continue? [Y/n] y Get:1 http://ppa.launchpad.net/git-core/ppa/ubuntu xenial/main amd64 git-man all 1:2.13.0-0ppa1~ubuntu16.04.1 [1448 kB] Get:2 http://ppa.launchpad.net/git-core/ppa/ubuntu xenial/main amd64 git amd64 1:2.13.0-0ppa1~ubuntu16.04.1 [4726 kB] Fetched 6174 kB in 19s (322 kB/s) perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:     LANGUAGE = (unset),     LC_ALL = (unset),     LC_TIME = &quot;zh_CN.UTF-8&quot;,     LC_MONETARY = &quot;zh_CN.UTF-8&quot;,     LC_CTYPE = &quot;UTF-8&quot;,     LC_ADDRESS = &quot;zh_CN.UTF-8&quot;,     LC_TELEPHONE = &quot;zh_CN.UTF-8&quot;,     LC_NAME = &quot;zh_CN.UTF-8&quot;,     LC_MEASUREMENT = &quot;zh_CN.UTF-8&quot;,     LC_IDENTIFICATION = &quot;zh_CN.UTF-8&quot;,     LC_NUMERIC = &quot;zh_CN.UTF-8&quot;,     LC_PAPER = &quot;zh_CN.UTF-8&quot;,     LANG = &quot;en_US.UTF-8&quot;     are supported and installed on your system. perl: warning: Falling back to a fallback locale (&quot;en_US.UTF-8&quot;). locale: Cannot set LC_CTYPE to default locale: No such file or directory locale: Cannot set LC_ALL to default locale: No such file or directory (Reading database ... 247161 files and directories currently installed.) Preparing to unpack .../git-man_1%3a2.13.0-0ppa1~ubuntu16.04.1_all.deb ... Unpacking git-man (1:2.13.0-0ppa1~ubuntu16.04.1) over (1:2.7.4-0ubuntu1.1) ... Selecting previously unselected package git. Preparing to unpack .../git_1%3a2.13.0-0ppa1~ubuntu16.04.1_amd64.deb ... Unpacking git (1:2.13.0-0ppa1~ubuntu16.04.1) ... Processing triggers for man-db (2.7.5-1) ... Setting up git-man (1:2.13.0-0ppa1~ubuntu16.04.1) ... Setting up git (1:2.13.0-0ppa1~ubuntu16.04.1) ...</code></pre></li><li><p>查看git版本</p><pre><code> johnathon@ubuntu16:~$ git --version git version 2.13.0</code></pre></li></ol><h2 id="配置Git"><a href="#配置Git" class="headerlink" title="配置Git"></a>配置Git</h2><ul><li>设置用户名和邮箱<pre><code>  johnathon@ubuntu16:~$ git config --global user.name &#39;*&#39;  johnathon@ubuntu16:~$ git config --global user.email &#39;*@*.com&#39;</code></pre></li><li>home目录下会生成.gitconfig文件,其内容正是上面步骤配置的信息<pre><code>  johnathon@ubuntu16:~$ ll .gitconfig  -rw-rw-r-- 1 johnathon johnathon 58 Jul 22 17:17 .gitconfig</code></pre></li></ul><h2 id="添加SSH-keys到github"><a href="#添加SSH-keys到github" class="headerlink" title="添加SSH keys到github"></a>添加SSH keys到github</h2><ul><li>运行下面命令，会在.ssh目录下生成相应文件<pre><code>  johnathon@ubuntu16:~$ ssh-keygen -t rsa -C &#39;youremail&#39;</code></pre></li><li>查看生成的私钥／公钥<pre><code>  johnathon@ubuntu16:~/.ssh$ ll  total 20  drwx------  2 johnathon johnathon 4096 Jul 22 17:25 ./  drwxr-xr-x 22 johnathon johnathon 4096 Jul 22 17:18 ../  -rw-------  1 johnathon johnathon 1675 Jul 22 17:25 id_rsa  -rw-r--r--  1 johnathon johnathon  404 Jul 22 17:25 id_rsa.pub  -rw-r--r--  1 johnathon johnathon  222 Jul  1 21:41 known_hosts</code></pre></li><li>将id_rsa.pub中内容拷贝到github中,如下图<img src="/img/sshkey170722.png"></li></ul>]]></content>
      
      
      <categories>
          
          <category> tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Use pyspark with python3</title>
      <link href="/2017/07/17/use-pyspark-with-python3/"/>
      <url>/2017/07/17/use-pyspark-with-python3/</url>
      
        <content type="html"><![CDATA[<img src="/img/spark.jpg" width="500" height="350"><span id="more"></span><ol><li><p>edit profile :vim ~/.profile</p></li><li><p>add the code into the file: export PYSPARK_PYTHON=python3</p></li><li><p>execute command :  source ~/.profile</p></li><li><p>./bin/pyspark</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> BigData </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu16.04 Install Sqoop1.4.6</title>
      <link href="/2017/07/16/ubuntu16-04-install-sqoop1-4-6/"/>
      <url>/2017/07/16/ubuntu16-04-install-sqoop1-4-6/</url>
      
        <content type="html"><![CDATA[<img src="/img/sqoop.jpg" width="500" height="350"><span id="more"></span>## 安装环境OS: linux(ubuntu16.04)sqoop version: 1.4.6hadoop version: 2.8.0mysql version: 5.7.18<h2 id="下载解压sqoop1-4-6"><a href="#下载解压sqoop1-4-6" class="headerlink" title="下载解压sqoop1.4.6"></a>下载解压sqoop1.4.6</h2><ul><li><p>前往sqoop官网<a href="http://mirror.bit.edu.cn/apache/sqoop/">下载</a>,默认下载目录为当前用户Downloads目录</p><pre><code>  johnathon@ubuntu16:~$ cd Downloads/  johnathon@ubuntu16:~/Downloads$ sudo tar -zxf sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz -C /usr/local  johnathon@ubuntu16:~/Downloads$ cd /usr/local  johnathon@ubuntu16:/usr/local$ sudo mv sqoop-1.4.6.bin__hadoop-2.0.4-alpha sqoop   johnathon@ubuntu16:/usr/local$ sudo chown -R hadoop:hadoop sqoop </code></pre></li></ul><h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><ol><li><p>打开sqoop-env.sh</p><pre><code> hadoop@ubuntu16:~$ cd /usr/local/sqoop/conf/ hadoop@ubuntu16:/usr/local/sqoop/conf$ cp sqoop-env-template.sh sqoop-env.sh hadoop@ubuntu16:/usr/local/sqoop/conf$ vi sqoop-env.sh</code></pre></li><li><p>添加以下信息</p><pre><code>  export HADOOP_COMMON_HOME=/usr/local/hadoop  export HADOOP_MAPRED_HOME=/usr/local/hadoop  export HIVE_HOME=/usr/local/hive</code></pre></li></ol><h2 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h2><ol><li><p>打开~/.bashrc文件</p><pre><code> hadoop@ubuntu16:~$ vi ~/.bashrc</code></pre></li><li><p>添加以下信息</p><pre><code> export SQOOP_HOME=/usr/local/sqoop export PATH=$PATH:$SBT_HOME/bin:$SQOOP_HOME/bin export CLASSPATH=$CLASSPATH:$SQOOP_HOME/lib</code></pre></li><li><p>使修改生效</p><pre><code> hadoop@ubuntu16:~$ source ~/.bashrc</code></pre></li><li><p>添加mysql驱动到$SQOOP_HOME/lib下</p><pre><code> johnathon@ubuntu16:~/Downloads/mysql-connector-java-5.1.42$ sudo cp mysql-connector-java-5.1.42-bin.jar /usr/local/sqoop/lib/ [sudo] password for johnathon: johnathon@ubuntu16:~/Downloads/mysql-connector-java-5.1.42$ cd /usr/local/sqoop/lib/ johnathon@ubuntu16:/usr/local/sqoop/lib$ ll mysql-connector-java-5.1.42-bin.jar  -rw-r--r-- 1 root root 996444 Jul 16 17:25 mysql-connector-java-5.1.42-bin.jar</code></pre></li><li><p>测试连接mysql</p></li></ol><ul><li><p>测试命令</p><pre><code>  sqoop list-databases --connect jdbc:mysql://127.0.0.1:3306/ --username root -P</code></pre></li><li><p>mysql数据库显示如下，则连接成功</p><pre><code>  hadoop@ubuntu16:~$ sqoop list-databases --connect jdbc:mysql://127.0.0.1:3306/ --username root -P  Warning: /usr/local/sqoop/../hbase does not exist! HBase imports will fail.  Please set $HBASE_HOME to the root of your HBase installation.  Warning: /usr/local/sqoop/../hcatalog does not exist! HCatalog jobs will fail.  Please set $HCAT_HOME to the root of your HCatalog installation.  Warning: /usr/local/sqoop/../accumulo does not exist! Accumulo imports will fail.  Please set $ACCUMULO_HOME to the root of your Accumulo installation.  Warning: /usr/local/sqoop/../zookeeper does not exist! Accumulo imports will fail.  Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.  17/07/16 18:04:06 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6  Enter password:  17/07/16 18:04:12 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.  Sun Jul 16 18:04:12 CST 2017 WARN: Establishing SSL connection without server&#39;s identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn&#39;t set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to &#39;false&#39;. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.  information_schema  hive  mysql  performance_schema  sys</code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> BigData </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Problems in Using Hive</title>
      <link href="/2017/07/15/probles-in-using-hive/"/>
      <url>/2017/07/15/probles-in-using-hive/</url>
      
        <content type="html"><![CDATA[<img src="/img/hive_bug.jpg" width="500" height="350"><span id="more"></span><p>在使用beeline方式连接hive时，遇到的一个坑，困扰多时，在网上也搜了好久，还好没放弃，今天终于找到了答案，在此非常感谢**<a href="http://blog.csdn.net/sunnyyoona/article/details/51648871"> [Hive]那些年我们踩过的Hive坑</a>**(如有侵犯，还望告知),我的问题就是其中的第10个问题。</p><h2 id="Question01"><a href="#Question01" class="headerlink" title="Question01"></a>Question01</h2><ul><li><p>问题:</p><pre><code>  Error: Could not open client transport with JDBC Uri: jdbc:hive2://192.168.140.128:10000/default: Failed to open new session: java.lang.RuntimeException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.authorize.AuthorizationException): User: hadoop is not allowed to impersonate hive (state=08S01,code=0)</code></pre></li><li><p>解决方法:<br>修改hadoop 配置文件 etc/hadoop/core-site.xml,加入如下配置项</p><pre><code>  &lt;property&gt;       &lt;name&gt;hadoop.proxyuser.hadoop.hosts&lt;/name&gt;       &lt;value&gt;*&lt;/value&gt;       &lt;description&gt;The superuser can connect only from host1 and host2 to impersonate a user&lt;/description&gt;  &lt;/property&gt;   &lt;property&gt;       &lt;name&gt;hadoop.proxyuser.hadoop.groups&lt;/name&gt;       &lt;value&gt;*&lt;/value&gt;       &lt;description&gt;Allow the superuser oozie to impersonate any members of the group group1 and group2&lt;/description&gt;  &lt;/property&gt;</code></pre></li></ul><p>需要注意的是：hadoop.proxyuser.?.hosts 和 hadoop.proxyuser.?.groups中的 ? 和报错信息 User: ? is not allowed to impersonate hive (state=08S01,code=0)中的? 相对应，我这里是hadoop,所以我填的是hadoop.</p>]]></content>
      
      
      <categories>
          
          <category> BigData </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Install and Configure Hive2.1.1</title>
      <link href="/2017/07/08/install-and-configure-hive2-1-1/"/>
      <url>/2017/07/08/install-and-configure-hive2-1-1/</url>
      
        <content type="html"><![CDATA[<img src="/img/hive.png" width="500" height="350"><span id="more"></span><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><ol><li>安装jdk 参考<a href="%E9%85%8D%E7%BD%AE%E7%9B%B8%E5%85%B3/ubuntu-install-jdk-without-source-everytime-open-a-new-shell/">Ubuntu16.04 Install and Configure Oracle JDK</a></li><li>安装Hadoop 参考<a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%EF%BC%8FUbuntu16-04-Install-Hadoop-2-8-0%EF%BC%8F">Ubuntu16.04 Install Hadoop 2.8.0</a></li></ol><h2 id="下载hive安装包"><a href="#下载hive安装包" class="headerlink" title="下载hive安装包"></a>下载hive安装包</h2><p>前往hive官方<a href="http://hive.apache.org/downloads.html">下载地址</a></p><h2 id="解压安装hive"><a href="#解压安装hive" class="headerlink" title="解压安装hive"></a>解压安装hive</h2><ol><li>解压hive安装文件到相应的目录<pre><code> hadoop@ubuntu16:~$ sudo tar -zxf apache-hive-2.1.1-bin.tar.gz -C /usr/local</code></pre></li><li>给hive目录重命名<pre><code> hadoop@ubuntu16:~$ cd /usr/local hadoop@ubuntu16:/usr/local$ sudo mv apache-hive-2.1.1-bin/ hive</code></pre></li><li>将hive目录用户改为hadoop<pre><code> hadoop@ubuntu16:/usr/local$ sudo chown -R hadoop hive/</code></pre></li><li>查看hive目录<pre><code> hadoop@ubuntu16:/usr/local$ cd hive/ hadoop@ubuntu16:/usr/local/hadoop$ ls -l hadoop@ubuntu16:/usr/local/hive$ ll total 112 drwxr-xr-x 10 hadoop root    4096 Jul  8 22:11 ./ drwxr-xr-x 12 root   root    4096 Jul  8 20:11 ../ -rw-r--r--  1 hadoop staff  29003 Nov 29  2016 LICENSE -rw-r--r--  1 hadoop staff    578 Nov 29  2016 NOTICE -rw-r--r--  1 hadoop staff   4122 Nov 29  2016 README.txt -rw-r--r--  1 hadoop staff  18501 Nov 30  2016 RELEASE_NOTES.txt drwxr-xr-x  3 hadoop root    4096 Jul  8 20:11 bin/ drwxr-xr-x  3 hadoop root    4096 Jul  8 22:15 conf/ drwxr-xr-x  4 hadoop root    4096 Jul  8 20:11 examples/ drwxr-xr-x  7 hadoop root    4096 Jul  8 20:11 hcatalog/ drwxr-xr-x  2 hadoop root    4096 Jul  8 20:11 jdbc/ drwxr-xr-x  4 hadoop root   12288 Jul  8 21:10 lib/ drwxr-xr-x  4 hadoop root    4096 Jul  8 20:11 scripts/ drwxrwxr-x  3 hadoop hadoop  4096 Jul  8 22:19 tmp/</code></pre></li></ol><h2 id="设置hive环境变量"><a href="#设置hive环境变量" class="headerlink" title="设置hive环境变量"></a>设置hive环境变量</h2><ol><li><p>打开~/.bashrc文件，并添加如下</p><pre><code> # set hive env start export HIVE_HOME=/usr/local/hive export PATH=$PATH:$HIVE_HOME/bin export PATH=$PATH:$HIVE_HOME/hcatalog/bin:$HIVE_HOME/hcatalog/sbin export CLASSPATH=$CLASSPATH:$HIVE_HOME/lib export HIVE_CONF_DIR=$HIVE_HOME/conf # set hive env end</code></pre></li><li><p>使配置文件生效</p><pre><code> hadoop@ubuntu16:~$ source ~/.bashrc</code></pre></li></ol><h2 id="配置hive"><a href="#配置hive" class="headerlink" title="配置hive"></a>配置hive</h2><ol><li><p>修改默认配置文件名使配置文件生效</p><pre><code> hadoop@ubuntu16:~$ cd /usr/local/hive/conf/ hadoop@ubuntu16:/usr/local/hive/conf$ cp hive-env.sh.template hive-env.sh hadoop@ubuntu16:/usr/local/hive/conf$ cp hive-default.xml.template hive-site.xml hadoop@ubuntu16:/usr/local/hive/conf$ cp hive-log4j2.properties.template hive-log4j2.properties hadoop@ubuntu16:/usr/local/hive/conf$ cp hive-exec-log4j2.properties.template hive-exec-log4j2.properties</code></pre></li><li><p>修改hive-env.sh,添加如下</p><pre><code> export JAVA_HOME=/home/johnathon/Java/jdk1.8.0_131 export HADOOP_HOME=/usr/local/hadoop export HIVE_HOME=/usr/local/hive export HIVE_CONF_DIR=/usr/local/hive/conf</code></pre></li><li><p>创建hdfs目录</p><pre><code> hadoop@ubuntu16:~$ hdfs dfs -mkdir -p /user/hive/warehouse hadoop@ubuntu16:~$ hdfs dfs -mkdir -p /user/hive/tmp hadoop@ubuntu16:~$ hdfs dfs -mkdir -p /user/hive/log hadoop@ubuntu16:~$ hdfs dfs -chmod -R 777 /user/hive/warehouse hadoop@ubuntu16:~$ hdfs DFS -chmod -R 777 /user/hive/tmp hadoop@ubuntu16:~$ hdfs dfs -chmod -R 777 /user/hive/log hadoop@ubuntu16:~$ hdfs dfs -ls /user/hive Found 3 items drwxrwxrwx   - hadoop supergroup          0 2017-07-08 20:50 /user/hive/log drwxrwxrwx   - hadoop supergroup          0 2017-07-08 21:54 /user/hive/tmp drwxrwxrwx   - hadoop supergroup          0 2017-07-08 20:50 /user/hive/warehouse</code></pre></li><li><p>本地建立tmp目录</p><pre><code> hadoop@ubuntu16:/usr/local/hive$ mkdir tmp</code></pre></li><li><p>安装mysql数据库，并作相关配置<br>获取最近的软件包的列表</p><pre><code> hadoop@ubuntu16:~$ sudo apt-get update</code></pre><p>安装mysql服务和客户端，中间会要求输入root密码</p><pre><code> hadoop@ubuntu16:~$ sudo apt-get install mysql-server mysql-client</code></pre><p>root登陆mysql</p><pre><code> hadoop@ubuntu16:~$ mysql -u root -p</code></pre><p>创建hive用户</p><pre><code> mysql&gt; create user &#39;hive&#39; identified by &#39;hive&#39;;</code></pre><p>查看数据库</p><pre><code> mysql&gt; show databases;</code></pre><p>创建数据库命名为hive</p><pre><code> mysql&gt; create database hive;</code></pre><p>为hive用户授权</p><pre><code> mysql&gt; grant all privileges on *.* to &#39;hive&#39;@&#39;localhost&#39; identified by &#39;hive&#39;; mysql&gt; flush privileges</code></pre><p>退出root登陆</p><pre><code> mysql&gt; exit;</code></pre><p>hive用户登录</p><pre><code> hadoop@ubuntu16:~$ mysql -u hive -p Enter password: Welcome to the MySQL monitor.  Commands end with ; or \g. Your MySQL connection id is 67 Server version: 5.7.18-0ubuntu0.16.04.1 (Ubuntu) Copyright (c) 2000, 2017, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type &#39;help;&#39; or &#39;\h&#39; for help. Type &#39;\c&#39; to clear the current input statement. mysql&gt;</code></pre></li><li><p>修改hive-site.xml文件</p></li><li><p>1 相关目录信息</p><pre><code>  &lt;property&gt;      &lt;name&gt;hive.exec.scratchdir&lt;/name&gt;      &lt;value&gt;/user/hive/tmp&lt;/value&gt;      &lt;description&gt;HDFS root scratch dir for Hive jobs which gets created with write all (733) permission. For each connecting user, an HDFS scratch dir: $&#123;hive.exec.scratchdir&#125;/&amp;lt;username&amp;gt; is created, with $&#123;hive.scratch.dir.permission&#125;.&lt;/description&gt;  &lt;/property&gt;    &lt;property&gt;      &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;      &lt;value&gt;/user/hive/warehouse&lt;/value&gt;      &lt;description&gt;location of default database for the warehouse&lt;/description&gt;    &lt;/property&gt;  &lt;property&gt;      &lt;name&gt;hive.querylog.location&lt;/name&gt;      &lt;value&gt;/user/hive/log&lt;/value&gt;      &lt;description&gt;Location of Hive run time structured log file&lt;/description&gt;  &lt;/property&gt;</code></pre></li><li><p>2 ${system:java.io.tmpdir} 和 ${system:user.name} 分别替换成 /user/local/hive/tmp 和 ${user.name}</p></li><li><p>3 mysql数据库连接信息,需要将mysql的jar包放入hive/lib目录下</p><pre><code>  &lt;property&gt;      &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;      &lt;value&gt;jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true&amp;amp;characterEncoding=UTF-8&amp;amp;useSSL=false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;      &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;      &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;      &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;      &lt;value&gt;hive&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;      &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;      &lt;value&gt;hive&lt;/value&gt;  &lt;/property&gt;</code></pre></li></ol><h2 id="启动hive"><a href="#启动hive" class="headerlink" title="启动hive"></a>启动hive</h2><ul><li><pre><code>  hadoop@ubuntu16:~$ hive  SLF4J: Class path contains multiple SLF4J bindings.  SLF4J: Found binding in [jar:file:/usr/local/hive/lib/log4j-slf4j-impl-2.4.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]  SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]  SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.  SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]  Logging initialized using configuration in file:/usr/local/hive/conf/hive-log4j2.properties Async: true  Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.  hive&gt;</code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> BigData </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hive </tag>
            
            <tag> mysql </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu16.04 Install Hadoop 2.8.0</title>
      <link href="/2017/07/02/ubuntu16-04-install-hadoop-2-8-0/"/>
      <url>/2017/07/02/ubuntu16-04-install-hadoop-2-8-0/</url>
      
        <content type="html"><![CDATA[<img src="/img/hadoop.jpg" width="500" height="350"><span id="more"></span>## 创建hadoop用户1. 创建用户hadoop,并且用/bin/bash作为默认shell：        johnathon@ubuntu16:~$ sudo useradd -m hadoop -s /bin/bash2. 为用户hadoop设置密码：        johnathon@ubuntu16:~$ sudo passwd hadoop3. 将用户hadoop加入sudo组：        johnathon@ubuntu16:~$ sudo adduser hadoop sudo<h2 id="更新apt"><a href="#更新apt" class="headerlink" title="更新apt"></a>更新apt</h2><ul><li><pre><code>  hadoop@ubuntu16:~$ sudo apt-get update</code></pre></li></ul><h2 id="配置ssh免密登陆"><a href="#配置ssh免密登陆" class="headerlink" title="配置ssh免密登陆"></a>配置ssh免密登陆</h2><ol><li>安装ssh服务<pre><code> hadoop@ubuntu16:~$ sudo apt-get install ssh</code></pre></li><li>创建.ssh目录<pre><code> hadoop@ubuntu16:~$ cd ~ hadoop@ubuntu16:~$ mkdir .ssh</code></pre></li><li>生成ssh密钥<pre><code> hadoop@ubuntu16:~$ cd .ssh/ hadoop@ubuntu16:~$ ssh-keygen -t rsa hadoop@ubuntu16:~/.ssh$ cat id_rsa.pub &gt;&gt; authorized_keys</code></pre></li><li>ssh登陆localhost<pre><code> hadoop@ubuntu16:~/.ssh$ cd hadoop@ubuntu16:~$ ssh localhost</code></pre></li><li>退出ssh登陆<pre><code>hadoop@ubuntu16:~$ exitlogoutConnection to localhost closed.</code></pre></li></ol><h2 id="安装配置jdk"><a href="#安装配置jdk" class="headerlink" title="安装配置jdk"></a>安装配置jdk</h2><ul><li>参考<a href="%E9%85%8D%E7%BD%AE%E7%9B%B8%E5%85%B3/ubuntu-install-jdk-without-source-everytime-open-a-new-shell/">Ubuntu16.04 Install and Configure Oracle JDK</a></li></ul><h2 id="安装hadoop"><a href="#安装hadoop" class="headerlink" title="安装hadoop"></a>安装hadoop</h2><ol><li><p>解压hadoop安装文件到相应的目录</p><pre><code> hadoop@ubuntu16:~$ sudo tar -zxf hadoop-2.8.0.tar.gz -C /usr/local</code></pre></li><li><p>给hadoop目录重命名</p><pre><code> hadoop@ubuntu16:~$ cd /usr/local hadoop@ubuntu16:/usr/local$ sudo mv hadoop-2.8.0/ hadoop</code></pre></li><li><p>将hadoop目录用户改为hadoop</p><pre><code>     hadoop@ubuntu16:/usr/local$ sudo chown -R hadoop hadoop/</code></pre></li><li><p>查看hadoop目录</p><pre><code> hadoop@ubuntu16:/usr/local$ cd hadoop/ hadoop@ubuntu16:/usr/local/hadoop$ ls -l total 148 -rw-r--r-- 1 hadoop dialout 99253 Mar 17 13:31 LICENSE.txt -rw-r--r-- 1 hadoop dialout 15915 Mar 17 13:31 NOTICE.txt -rw-r--r-- 1 hadoop dialout  1366 Mar 17 13:31 README.txt drwxr-xr-x 2 hadoop dialout  4096 Mar 17 13:31 bin drwxr-xr-x 3 hadoop dialout  4096 Mar 17 13:31 etc drwxr-xr-x 2 hadoop dialout  4096 Mar 17 13:31 include drwxr-xr-x 3 hadoop dialout  4096 Mar 17 13:31 lib drwxr-xr-x 2 hadoop dialout  4096 Mar 17 13:31 libexec drwxr-xr-x 2 hadoop dialout  4096 Mar 17 13:31 sbin drwxr-xr-x 4 hadoop dialout  4096 Mar 17 13:31 share</code></pre></li><li><p>查看hadoop版本信息</p><pre><code> hadoop@ubuntu16:/usr/local/hadoop$ ./bin/hadoop version Hadoop 2.8.0 Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r 91f2b7a13d1e97be65db92ddabc627cc29ac0009 Compiled by jdu on 2017-03-17T04:12Z Compiled with protoc 2.5.0 From source with checksum 60125541c2b3e266cbf3becc5bda666 This command was run using /usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.0.jar</code></pre></li><li><p>设置hadoop环境变量<br> 6.1. 打开hadoop用户下配置文件</p><pre><code> hadoop@ubuntu16:~$ vi .bashrc</code></pre><p> 6.2. 编辑文件，添加如下</p><pre><code> #set hadoop env begin export HADOOP_HOME=/usr/local/hadoop export PATH=$PATH:$HADOOP_HOME/bin export PATH=$PATH:$JAVA_HOME/bin export PATH=$PATH:$HADOOP_HOME/sbin #set hadoop env end</code></pre><p> 6.3. 使文件修改生效</p><pre><code> hadoop@ubuntu16:~$ source .bashrc</code></pre><p> 6.4. 查看hadoop版本信息（注意：与上一步骤中查看版本信息的区别）</p><pre><code> hadoop@ubuntu16:~$ hadoop version Hadoop 2.8.0 Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r 91f2b7a13d1e97be65db92ddabc627cc29ac0009 Compiled by jdu on 2017-03-17T04:12Z Compiled with protoc 2.5.0 From source with checksum 60125541c2b3e266cbf3becc5bda666 This command was run using /usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.0.jar</code></pre></li></ol><h2 id="配置hadoop伪分布式"><a href="#配置hadoop伪分布式" class="headerlink" title="配置hadoop伪分布式"></a>配置hadoop伪分布式</h2><p>配置hadoop伪分布式需要修改相关配置文件：hadoop-env.xml/core-site.xml/hdfs-site.xml</p><h2 id="hadoop配置文件位置：hadoop主目录下的-etc-hadoop-如下"><a href="#hadoop配置文件位置：hadoop主目录下的-etc-hadoop-如下" class="headerlink" title="hadoop配置文件位置：hadoop主目录下的/etc/hadoop,如下"></a>hadoop配置文件位置：hadoop主目录下的/etc/hadoop,如下</h2><pre><code>    hadoop@ubuntu16:/usr/local/hadoop/etc/hadoop$ ls    capacity-scheduler.xml      httpfs-env.sh            mapred-env.sh    configuration.xsl           httpfs-log4j.properties  mapred-queues.xml.template    container-executor.cfg      httpfs-signature.secret  mapred-site.xml    core-site.xml               httpfs-site.xml          mapred-site.xml.template    hadoop-env.cmd              kms-acls.xml             slaves    hadoop-env.sh               kms-env.sh               ssl-client.xml.example    hadoop-metrics.properties   kms-log4j.properties     ssl-server.xml.example    hadoop-metrics2.properties  kms-site.xml             yarn-env.cmd    hadoop-policy.xml           log4j.properties         yarn-env.sh    hdfs-site.xml               mapred-env.cmd           yarn-site.xml</code></pre><h3 id="修改相应的配置文件"><a href="#修改相应的配置文件" class="headerlink" title="修改相应的配置文件"></a>修改相应的配置文件</h3><ol><li><p>打开hadoop-env.sh</p><pre><code> hadoop@ubuntu16:/usr/local/hadoop/etc/hadoop$ vi hadoop-env.sh</code></pre></li><li><p>找到以下位置，把java目录修改为自己的主目录</p><pre><code>  # The java implementation to use.  export JAVA_HOME=$&#123;JAVA_HOME&#125;</code></pre></li><li><p>打开core-site.xml,并添加configuration内容</p><pre><code> hadoop@ubuntu16:/usr/local/hadoop/etc/hadoop$ vi core-site.xml</code></pre></li></ol><ul><li><pre><code>  &lt;configuration&gt;          &lt;property&gt;                  &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;                  &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt;                  &lt;description&gt;Abase for other temporary directories&lt;/description&gt;          &lt;/property&gt;          &lt;property&gt;                  &lt;name&gt;fs.defaultFS&lt;/name&gt;                  &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;          &lt;/property&gt;  &lt;/configuration&gt;</code></pre></li></ul><ol start="4"><li>打开hdfs-site.xml,并添加configuration内容<pre><code> hadoop@ubuntu16:/usr/local/hadoop/etc/hadoop$ vi hdfs-site.xml</code></pre></li></ol><ul><li><pre><code>  &lt;configuration&gt;          &lt;property&gt;                  &lt;name&gt;dfs.replication&lt;/name&gt;                  &lt;value&gt;1&lt;/value&gt;          &lt;/property&gt;          &lt;property&gt;                  &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;                  &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;/value&gt;          &lt;/property&gt;          &lt;property&gt;                  &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;                  &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/data&lt;/value&gt;          &lt;/property&gt;  &lt;/configuration&gt;</code></pre></li></ul><h3 id="格式化namenode"><a href="#格式化namenode" class="headerlink" title="格式化namenode"></a>格式化namenode</h3><ul><li><pre><code>  hadoop@ubuntu16:~$ hdfs namenode -format</code></pre></li></ul><h3 id="启动NameNode和DataNode进程"><a href="#启动NameNode和DataNode进程" class="headerlink" title="启动NameNode和DataNode进程"></a>启动NameNode和DataNode进程</h3><ul><li><pre><code>  hadoop@ubuntu16:~$ start-dfs.sh  Starting namenodes on [localhost]  localhost: starting namenode, logging to /usr/local/hadoop/logs/hadoop-hadoop-namenode-ubuntu16.out  localhost: starting datanode, logging to /usr/local/hadoop/logs/hadoop-hadoop-datanode-ubuntu16.out  Starting secondary namenodes [0.0.0.0]  0.0.0.0: starting secondarynamenode, logging to /usr/local/hadoop/logs/hadoop-hadoop-secondarynamenode-ubuntu16.out  hadoop@ubuntu16:~$ jps  41749 NameNode  42203 Jps  42092 SecondaryNameNode  41903 DataNode</code></pre></li></ul><h3 id="访问web界面"><a href="#访问web界面" class="headerlink" title="访问web界面"></a>访问web界面</h3><p>输入主机ip:50070,访问主界面，如下<br>    <img src="/img/hadoop_50070.jpg" width="500" height="300"></p><h3 id="运行hadoop实例"><a href="#运行hadoop实例" class="headerlink" title="运行hadoop实例"></a>运行hadoop实例</h3><ol><li><p>创建目录</p><pre><code> hadoop@ubuntu16:~$ hdfs dfs -mkdir /user/hadoop hadoop@ubuntu16:~$ hdfs dfs -mkdir input</code></pre></li><li><p>将本地文件拷贝到hdfs下input目录（发现有警告信息，目前还没有找到解决方法，不管不影响运行结果）</p><pre><code> hadoop@ubuntu16:~$ hdfs dfs -put /usr/local/hadoop/etc/hadoop/*.xml input 17/07/08 16:00:09 WARN hdfs.DataStreamer: Caught exception java.lang.InterruptedException     at java.lang.Object.wait(Native Method)     at java.lang.Thread.join(Thread.java:1252)     at java.lang.Thread.join(Thread.java:1326)     at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:927)     at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:578)     at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:755) 17/07/08 16:00:09 WARN hdfs.DataStreamer: Caught exception java.lang.InterruptedException     at java.lang.Object.wait(Native Method)     at java.lang.Thread.join(Thread.java:1252)     at java.lang.Thread.join(Thread.java:1326)     at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:927)     at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:578)     at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:755) 17/07/08 16:00:09 WARN hdfs.DataStreamer: Caught exception java.lang.InterruptedException     at java.lang.Object.wait(Native Method)     at java.lang.Thread.join(Thread.java:1252)     at java.lang.Thread.join(Thread.java:1326)     at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:927)     at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:578)     at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:755) 17/07/08 16:00:09 WARN hdfs.DataStreamer: Caught exception java.lang.InterruptedException     at java.lang.Object.wait(Native Method)     at java.lang.Thread.join(Thread.java:1252)     at java.lang.Thread.join(Thread.java:1326)     at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:927)     at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:578)     at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:755) hadoop@ubuntu16:~$ hdfs dfs -ls Found 1 items drwxr-xr-x   - hadoop supergroup          0 2017-07-08 16:00 input hadoop@ubuntu16:~$ hdfs dfs -ls input Found 8 items -rw-r--r--   1 hadoop supergroup       4942 2017-07-08 16:00 input/capacity-scheduler.xml -rw-r--r--   1 hadoop supergroup       1032 2017-07-08 16:00 input/core-site.xml -rw-r--r--   1 hadoop supergroup       9683 2017-07-08 16:00 input/hadoop-policy.xml -rw-r--r--   1 hadoop supergroup       1079 2017-07-08 16:00 input/hdfs-site.xml -rw-r--r--   1 hadoop supergroup        620 2017-07-08 16:00 input/httpfs-site.xml -rw-r--r--   1 hadoop supergroup       3518 2017-07-08 16:00 input/kms-acls.xml -rw-r--r--   1 hadoop supergroup       5546 2017-07-08 16:00 input/kms-site.xml -rw-r--r--   1 hadoop supergroup        794 2017-07-08 16:00 input/yarn-site.xml</code></pre></li><li><p>运行自带实例<br> hadoop@ubuntu16:~$ hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.0.jar grep input output ‘dfs[a-z.]+’</p></li><li><p>查看运行结果</p><pre><code> hadoop@ubuntu16:~$ hdfs dfs -ls Found 2 items drwxr-xr-x   - hadoop supergroup          0 2017-07-08 16:00 input drwxr-xr-x   - hadoop supergroup          0 2017-07-08 16:10 output hadoop@ubuntu16:~$ hdfs dfs -ls output Found 2 items -rw-r--r--   1 hadoop supergroup          0 2017-07-08 16:10 output/_SUCCESS -rw-r--r--   1 hadoop supergroup         77 2017-07-08 16:10 output/part-r-00000 hadoop@ubuntu16:~$ hdfs dfs -cat output/* 1    dfsadmin 1    dfs.replication 1    dfs.namenode.name.dir 1    dfs.datanode.data.dir</code></pre></li></ol><p><strong>NOTE</strong>: 再次运行前，需要删除掉output目录，否则会报错</p><h3 id="配置yarn"><a href="#配置yarn" class="headerlink" title="配置yarn"></a>配置yarn</h3><ol><li><p>打开yarn-site.xml,并添加如下configuration</p><pre><code> &lt;configuration&gt;     &lt;property&gt;         &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;         &lt;value&gt;mapreduce_shuffle&lt;/value&gt;     &lt;/property&gt; &lt;/configuration&gt;</code></pre></li><li><p>启动ResourceManager和NodeManager进程,jps可以看出比单独启动start-dfs.sh 多出来两个进程</p><pre><code> hadoop@ubuntu16:/usr/local/hadoop/etc/hadoop$ start-yarn.sh starting yarn daemons starting resourcemanager, logging to /usr/local/hadoop/logs/yarn-hadoop-resourcemanager-ubuntu16.out localhost: starting nodemanager, logging to /usr/local/hadoop/logs/yarn-hadoop-nodemanager-ubuntu16.out hadoop@ubuntu16:/usr/local/hadoop/etc/hadoop$ jps 46788 SecondaryNameNode 51397 NodeManager 46598 DataNode 46443 NameNode 51724 Jps 51276 ResourceManager</code></pre></li><li><p>启动历史进程</p><pre><code> hadoop@ubuntu16:/usr/local/hadoop/etc/hadoop$ mr-jobhistory-daemon.sh start historyserver starting historyserver, logging to /usr/local/hadoop/logs/mapred-hadoop-historyserver-ubuntu16.out</code></pre></li><li><p>访问web界面<br>输入主机ip:8088,访问主界面，如下</p><img src="/img/hadoop_8088.jpg" width='500' height='300'></li></ol><h3 id="关闭所有进程-和开启顺序相反"><a href="#关闭所有进程-和开启顺序相反" class="headerlink" title="关闭所有进程,和开启顺序相反"></a>关闭所有进程,和开启顺序相反</h3><ul><li><pre><code>  hadoop@ubuntu16:~$ mr-jobhistory-daemon.sh stop historyserver  stopping historyserver  hadoop@ubuntu16:~$ stop-yarn.sh  stopping yarn daemons  stopping resourcemanager  localhost: stopping nodemanager  localhost: nodemanager did not stop gracefully after 5 seconds: killing with kill -9  no proxyserver to stop  hadoop@ubuntu16:~$ stop-dfs.sh  Stopping namenodes on [localhost]  localhost: stopping namenode  localhost: stopping datanode  Stopping secondary namenodes [0.0.0.0]  0.0.0.0: stopping secondarynamenode</code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> BigData </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu16.04 Install and Configure Oracle JDK</title>
      <link href="/2017/07/01/ubuntu-install-jdk-without-source-everytime-open-a-new-shell/"/>
      <url>/2017/07/01/ubuntu-install-jdk-without-source-everytime-open-a-new-shell/</url>
      
        <content type="html"><![CDATA[<img src="/img/jdk8.jpg" width="500" height="350"><span id="more"></span>1. 查看系统位数，终端输入：        getconf LONG_BIT<ol start="2"><li><p>下载对应版本的jdk，这里下载的是jdk-8u131-linux-x64.tar.gz</p></li><li><p>创建目录作为jdk安装目录，这里选择安装位置为：~/Java（可自行选择安装路径）</p><pre><code> sudo mkdir Java</code></pre></li><li><p>解压文件到上一步创建的目录~/Java目录下,JDK默认下载路径为Downloads目录</p><pre><code> cd ~/Downloads sudo tar -zxvf jdk-8u131-linux-x64.tar.gz -C ~/Java</code></pre></li><li><p>配置系统环境变量(全局：/etc/profile|当前用户：~/.bashrc)</p><pre><code> sudo vi /etc/profile</code></pre><p> 在最后加入:</p><pre><code> ##config java environment start export JAVA_HOME=/home/johnathon/Java/jdk1.8.0_131 export JRE_HOME=$&#123;JAVA_HOME&#125;/jre export CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JAVA_HOME&#125;/jre/lib:$CLASSPATH export PATH=$&#123;JAVA_HOME&#125;/bin:$&#123;JAVA_HOME&#125;/jre/bin:$PATH ##config java environment end</code></pre><p> 修改完成后，保存并关闭，输入一下命令使环境变量生效</p><pre><code> source /etc/profile</code></pre></li><li><p>查看安装版本：</p><pre><code> java -version</code></pre></li><li><p>本以为到此就结束了，结果发现每次重新打开一个terminal，就找不到java环境，搜索发现做以下配置:</p><p> 配置/etc/bash.bashrc</p><pre><code> sudo vi /etc/bash.bashrc</code></pre><p> 在最后加入：</p><pre><code> ##config java environment start export JAVA_HOME=/home/johnathon/Java/jdk1.8.0_131 export JRE_HOME=$&#123;JAVA_HOME&#125;/jre export CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JAVA_HOME&#125;/jre/lib:$CLASSPATH export PATH=$&#123;JAVA_HOME&#125;/bin:$&#123;JAVA_HOME&#125;/jre/bin:$PATH ##config java environment end</code></pre><p> 改完成后，保存并关闭，输入一下命令使环境变量生效</p><pre><code> source /etc/bash.bashrc</code></pre></li><li><p>到此完成安装配置jdk。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 配置相关 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jdk </tag>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MacPro Connect Ubuntu16.04 In VWware Fusion</title>
      <link href="/2017/07/01/mac-connect-ubuntu-in-vwware-fusion/"/>
      <url>/2017/07/01/mac-connect-ubuntu-in-vwware-fusion/</url>
      
        <content type="html"><![CDATA[<img src="/img/fusion.jpg" width="500" height="350"><span id="more"></span># Mac 和 Linux虚拟机互通<h2 id="开启ssh服务"><a href="#开启ssh服务" class="headerlink" title="开启ssh服务"></a>开启ssh服务</h2><ol><li>查看是否安装ssh服务：<pre><code> ps -e | grep ssh</code></pre></li><li>安装ssh服务：<pre><code> sudo apt-get install ssh</code></pre></li></ol><h2 id="mac终端ssh连接Linux虚拟机"><a href="#mac终端ssh连接Linux虚拟机" class="headerlink" title="mac终端ssh连接Linux虚拟机:"></a>mac终端ssh连接Linux虚拟机:</h2><p>ssh user@remote[ip] </p><p>为了方便使用别名<strong>sshubt</strong>登陆</p><ol><li>编辑mac下.bash_profile文件(需要root权限):<pre><code> sudo vi ~/.bash_profile</code></pre></li><li>添加下面语句 <pre><code> alias sshubt=&#39;ssh myusername@192.168.0.0&#39;</code></pre></li><li>使用别名sshubt，输入连接到的Linux主机密码，登陆即可<pre><code> jockie:~$ sshubt johnathon@192.168.140.128&#39;s password: Welcome to Ubuntu 16.04.2 LTS (GNU/Linux 4.8.0-36-generic x86_64)</code></pre></li></ol><h2 id="mac上传文件址Linux虚拟机"><a href="#mac上传文件址Linux虚拟机" class="headerlink" title="mac上传文件址Linux虚拟机"></a>mac上传文件址Linux虚拟机</h2><pre><code>scp ~/local/file user@remtoe:~/file~/local/file: mac文件路径user@remote:~/file: 服务器文件路径</code></pre>]]></content>
      
      
      <categories>
          
          <category> 配置相关 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> ubuntu </tag>
            
            <tag> mac </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>long time no see</title>
      <link href="/2017/06/19/long-time-no-see/"/>
      <url>/2017/06/19/long-time-no-see/</url>
      
        <content type="html"><![CDATA[<img src="/img/supermanback.jpg" width="500" height="350"><p>It’s been almost 3 years since I met you ,hexo!</p><p>NOW,It’s Time to Come Back!!!</p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
